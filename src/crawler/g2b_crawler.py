"""G2B (ë‚˜ë¼ì¥í„°) API Crawler."""

import asyncio
import aiohttp
import json
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from urllib.parse import quote

from src.crawler.base import BaseCrawler
from src.config import settings
from src.database.connection import DatabaseManager
from src.utils.logger import get_logger

logger = get_logger(__name__)


class G2BCrawler(BaseCrawler):
    """ë‚˜ë¼ì¥í„°(G2B) API í¬ë¡¤ëŸ¬"""

    def __init__(self):
        super().__init__("G2B", "KR")
        self.api_key = settings.G2B_API_KEY
        self.encoded_api_key = self._prepare_service_key(self.api_key)

        # BidPublicInfoService ì„¤ì •
        self.api_base_url = "http://apis.data.go.kr/1230000/ad/BidPublicInfoService"
        self.operations = {
            "cnstwk": ("getBidPblancListInfoCnstwkPPSSrch", "ê³µì‚¬"),
            "servc": ("getBidPblancListInfoServcPPSSrch", "ìš©ì—­"),
            "thng": ("getBidPblancListInfoThngPPSSrch", "ë¬¼í’ˆ"),
            "frgcpt": ("getBidPblancListInfoFrgcptPPSSrch", "ì™¸ì"),
        }
        self.api_request_timeout = aiohttp.ClientTimeout(total=20)
        self.api_rate_limit_tps = 30
        self.api_rows_per_page = 50  # í˜ì´ì§€ í¬ê¸° ì¤„ì—¬ì„œ API ì œí•œ íšŒí”¼

        # ê³µê³µë°ì´í„°ê°œë°©í‘œì¤€ì„œë¹„ìŠ¤ ì„¤ì • (ë°±ì—…ìš©)
        self.standard_api_base_url = "http://apis.data.go.kr/1230000/ao/PubDataOpnStdService"
        self.standard_operation = "getDataSetOpnStdBidPblancInfo"

    async def login(self) -> bool:
        """API ê¸°ë°˜ì´ë¯€ë¡œ ë¡œê·¸ì¸ ë¶ˆí•„ìš”"""
        if not self.encoded_api_key:
            logger.warning("G2B API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            logger.warning("data.go.krì—ì„œ 'ëˆ„ë¦¬ì¥í„° ë¯¼ê°„ì…ì°°ê³µê³ ì„œë¹„ìŠ¤' API í‚¤ë¥¼ ë°œê¸‰ë°›ì•„ .env íŒŒì¼ì˜ G2B_API_KEYì— ì„¤ì •í•˜ì„¸ìš”.")
            return False

        logger.info("G2B API í‚¤ ì¸ì¦ ì¤€ë¹„ ì™„ë£Œ")
        return True

    def setup_driver(self):
        """API ê¸°ë°˜ì´ë¯€ë¡œ WebDriver ë¶ˆí•„ìš”"""
        logger.info("G2B API í¬ë¡¤ëŸ¬ - WebDriver ì„¤ì • ìŠ¤í‚µ")

    def teardown_driver(self):
        """API ê¸°ë°˜ì´ë¯€ë¡œ ì •ë¦¬ ì‘ì—… ë¶ˆí•„ìš”"""
        logger.info("G2B API í¬ë¡¤ëŸ¬ - WebDriver ì •ë¦¬ ìŠ¤í‚µ")

    async def search_bids(self, keywords: List[str]) -> List[Dict[str, Any]]:
        """ì…ì°° ì •ë³´ ê²€ìƒ‰"""
        if not self.encoded_api_key:
            logger.warning("G2B API í‚¤ê°€ ì—†ì–´ ê²€ìƒ‰ ë¶ˆê°€")
            return []

        all_results: List[Dict[str, Any]] = []

        try:
            # ì‚¬ìš©ì ì œê³µ í‚¤ì›Œë“œë§Œ ì‚¬ìš© (Seegene í‚¤ì›Œë“œ í™•ì¥ ë¹„í™œì„±í™”)
            search_keywords = keywords
            logger.info(f"ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ: {search_keywords}")

            # BidPublicInfoService API ê²€ìƒ‰ (ì¹´í…Œê³ ë¦¬ë³„)
            for category, (operation, label) in self.operations.items():
                log_label = label if label == category else f"{label}({category})"
                logger.info(f"ğŸ“¡ G2B BidPublicInfoService - {log_label} ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ ì‹œì‘")
                results = await self._search_bid_public_info(operation, category, search_keywords, display_name=label)
                if results:
                    logger.info(f"âœ… {log_label} ì¹´í…Œê³ ë¦¬ì—ì„œ {len(results)}ê±´ ìˆ˜ì§‘")
                all_results.extend(results)
                await asyncio.sleep(1)  # API í˜¸ì¶œ ê°„ê²© ì¡°ì •

            # ê³µê³µë°ì´í„°ê°œë°©í‘œì¤€ì„œë¹„ìŠ¤ APIë„ í•¨ê»˜ ê²€ìƒ‰í•˜ì—¬ ë³´ê°•
            standard_results = await self._search_standard_api(search_keywords)
            if standard_results:
                logger.info(f"ğŸ“¦ í‘œì¤€ APIì—ì„œ ì¶”ê°€ {len(standard_results)}ê±´ ìˆ˜ì§‘")
            all_results.extend(standard_results)

            # ì¤‘ë³µ ì œê±°
            unique_results = self._remove_duplicates(all_results)

            logger.info(f"G2B API ê²€ìƒ‰ ì™„ë£Œ: ì´ {len(unique_results)}ê±´")
            return unique_results

        except Exception as e:
            logger.error(f"G2B API ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return all_results

    async def _search_bid_public_info(
        self,
        operation: str,
        category: str,
        keywords: List[str],
        display_name: Optional[str] = None,
    ) -> List[Dict[str, Any]]:
        """BidPublicInfoService API ê²€ìƒ‰"""
        results: List[Dict[str, Any]] = []

        try:
            category_label = display_name or category
            if not self.encoded_api_key:
                logger.warning("ìœ íš¨í•œ G2B API í‚¤ê°€ ì—†ì–´ BidPublicInfoService í˜¸ì¶œì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                return results

            end_date = datetime.now()
            start_date = end_date - timedelta(days=30)  # 30ì¼ë¡œ ë‹¨ì¶•í•˜ì—¬ API ì œí•œ íšŒí”¼

            base_params = {
                "ServiceKey": self.encoded_api_key,
                "type": "json",
                "numOfRows": self.api_rows_per_page,
                "inqryDiv": "1",  # ë“±ë¡ì¼ì‹œ ê¸°ì¤€
                "inqryBgnDt": start_date.strftime("%Y%m%d0000"),  # ì‹œê°„ì„ 0000ìœ¼ë¡œ ê³ ì •
                "inqryEndDt": end_date.strftime("%Y%m%d2359"),    # ì‹œê°„ì„ 2359ë¡œ ê³ ì •
            }
            search_params = self._build_search_query_params(category, keywords, start_date, end_date)

            url = f"{self.api_base_url}/{operation}"
            timeout = self.api_request_timeout

            async with aiohttp.ClientSession(timeout=timeout) as session:
                page_no = 1
                total_count: Optional[int] = None

                while True:
                    request_params = {**base_params, **search_params, "pageNo": page_no}
                    json_data: Optional[Dict[str, Any]] = None
                    should_break = False

                    async with session.get(url, params=request_params) as response:
                        if response.status != 200:
                            logger.error(f"[{category_label}] API í˜¸ì¶œ ì‹¤íŒ¨: {response.status}")
                            should_break = True
                        else:
                            data = await response.text()
                            if not data.strip():
                                logger.warning(f"[{category_label}] APIì—ì„œ ë¹ˆ ì‘ë‹µ ìˆ˜ì‹  (page {page_no})")
                                should_break = True
                            else:
                                try:
                                    json_data = json.loads(data)
                                except json.JSONDecodeError:
                                    logger.error(
                                        f"[{category_label}] API ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‘ë‹µ ë‚´ìš©: {data[:200]}"
                                    )
                                    should_break = True

                    if should_break:
                        break

                    if json_data is None:
                        break

                    page_results = await self._parse_api_response(
                        json_data, category, keywords, display_name=display_name
                    )
                    if page_results:
                        results.extend(page_results)

                    if total_count is None:
                        total_count = self._extract_total_count(json_data)

                    if not page_results:
                        logger.info(f"[{category_label}] ë” ì´ìƒ ê²°ê³¼ê°€ ì—†ì–´ í˜ì´ì§€ ìˆœíšŒë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                        break

                    if total_count is not None and page_no * self.api_rows_per_page >= total_count:
                        break

                    page_no += 1
                    await asyncio.sleep(1 / self.api_rate_limit_tps)

        except Exception as e:
            logger.error(f"ì¹´í…Œê³ ë¦¬ '{category}' API ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")

        return results

    def _build_search_query_params(
        self,
        category: str,
        keywords: List[str],
        start_date: datetime,
        end_date: datetime,
    ) -> Dict[str, Any]:
        """ë‚˜ë¼ì¥í„° ê²€ìƒ‰ì¡°ê±´ì„ PPS ì „ìš© ê²€ìƒ‰ íŒŒë¼ë¯¸í„°ë¡œ ë§¤í•‘ (í‚¤ì›Œë“œ ê²€ìƒ‰ ê°•í™”)"""

        params: Dict[str, Any] = {
            "searchDtType": "1",  # 1: ë“±ë¡ì¼ì‹œ ê¸°ì¤€ ê²€ìƒ‰
            "searchBgnDt": start_date.strftime("%Y%m%d"),
            "searchEndDt": end_date.strftime("%Y%m%d"),
        }

        # í‚¤ì›Œë“œ ì •ë¦¬ ë° ê²€ì¦
        sanitized_keywords: List[str] = []
        seen = set()
        for keyword in keywords:
            if not keyword:
                continue
            cleaned = keyword.strip()
            if not cleaned or cleaned in seen:
                continue
            sanitized_keywords.append(cleaned)
            seen.add(cleaned)

        if sanitized_keywords:
            # G2B APIëŠ” OR ë¬¸ë²•ì„ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì²« ë²ˆì§¸ í‚¤ì›Œë“œë§Œ ëŒ€í‘œ ê²€ìƒ‰ì–´ë¡œ ì‚¬ìš©
            main_keyword = sanitized_keywords[0]

            params.update({
                "searchType": "1",  # 1: ê³µê³ ëª… ê²€ìƒ‰
                "searchWrd": main_keyword,
                "bidNtceNm": main_keyword,
                # ì¶”ê°€ ê²€ìƒ‰ ì˜µì…˜
                "searchCndtnType": "1",  # ê²€ìƒ‰ ì¡°ê±´ íƒ€ì…
                "kwdSearch": "Y",  # í‚¤ì›Œë“œ ê²€ìƒ‰ í™œì„±í™”
            })

            # ê°œë³„ í‚¤ì›Œë“œë¡œë„ ê²€ìƒ‰ (ë” ë„“ì€ ë²”ìœ„)
            for i, keyword in enumerate(sanitized_keywords[:3]):  # ìµœëŒ€ 3ê°œ í‚¤ì›Œë“œ
                if i == 0:
                    params[f"bidNtceNm01"] = keyword
                elif i == 1:
                    params[f"bidNtceNm02"] = keyword
                elif i == 2:
                    params[f"bidNtceNm03"] = keyword

            logger.info(f"ğŸ” G2B ëŒ€í‘œ ê²€ìƒ‰ì–´: {main_keyword}")
            if len(sanitized_keywords) > 1:
                logger.info(f"ğŸ“‹ ì¶”ê°€ í‚¤ì›Œë“œëŠ” ê°œë³„ íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬: {sanitized_keywords[1:]}")
            logger.info(f"ğŸ“‹ ì „ì²´ ê²€ìƒ‰ í‚¤ì›Œë“œ: {sanitized_keywords}")
        else:
            # í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì „ì²´ ê²€ìƒ‰
            params.update({
                "searchType": "0",  # 0: ì „ì²´ ê²€ìƒ‰
                "kwdSearch": "N"
            })
            logger.info("ğŸ“¥ G2B ì „ì²´ ê²€ìƒ‰ (í‚¤ì›Œë“œ ë¯¸ì§€ì •)")

        return params

    async def _search_standard_api(self, keywords: List[str]) -> List[Dict[str, Any]]:
        """ê³µê³µë°ì´í„°ê°œë°©í‘œì¤€ì„œë¹„ìŠ¤ API ê²€ìƒ‰ (í‚¤ì›Œë“œ ê¸°ë°˜)"""
        results: List[Dict[str, Any]] = []

        try:
            if not self.encoded_api_key:
                logger.warning("ìœ íš¨í•œ G2B API í‚¤ê°€ ì—†ì–´ í‘œì¤€ API í˜¸ì¶œì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                return results

            end_date = datetime.now()
            start_date = end_date - timedelta(days=30)  # 30ì¼ë¡œ ë‹¨ì¶•í•˜ì—¬ API ì œí•œ íšŒí”¼

            # ê¸°ë³¸ ë§¤ê°œë³€ìˆ˜
            base_params = {
                "ServiceKey": self.encoded_api_key,
                "type": "json",
                "numOfRows": self.api_rows_per_page,
                "pageNo": 1,
                "bidNtceBgnDt": start_date.strftime("%Y%m%d0000"),
                "bidNtceEndDt": end_date.strftime("%Y%m%d2359"),
            }

            # í‚¤ì›Œë“œ ê²€ìƒ‰ ë§¤ê°œë³€ìˆ˜ ì¶”ê°€
            if keywords:
                # í‚¤ì›Œë“œ ì •ë¦¬
                sanitized_keywords = [kw.strip() for kw in keywords if kw.strip()]

                if sanitized_keywords:
                    # ì²« ë²ˆì§¸ í‚¤ì›Œë“œë¥¼ ë©”ì¸ ê²€ìƒ‰ì–´ë¡œ ì‚¬ìš©
                    main_keyword = sanitized_keywords[0]
                    base_params.update({
                        "bidNtceNm": main_keyword,  # ê³µê³ ëª… ê²€ìƒ‰
                        "searchWrd": main_keyword,   # ê²€ìƒ‰ì–´
                    })
                    logger.info(f"ğŸ” í‘œì¤€ API í‚¤ì›Œë“œ ê²€ìƒ‰: {main_keyword}")
                else:
                    logger.info("ğŸ“‹ í‘œì¤€ API ì „ì²´ ê²€ìƒ‰ (ìœ íš¨í•œ í‚¤ì›Œë“œ ì—†ìŒ)")
            else:
                logger.info("ğŸ“‹ í‘œì¤€ API ì „ì²´ ê²€ìƒ‰ (í‚¤ì›Œë“œ ë¯¸ì œê³µ)")

            params = base_params

            logger.info(f"ğŸ” í‘œì¤€ API ê²€ìƒ‰ - ê¸°ê°„: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}")

            async with aiohttp.ClientSession(timeout=self.api_request_timeout) as session:
                url = f"{self.standard_api_base_url}/{self.standard_operation}"

                async with session.get(url, params=params) as response:
                    if response.status != 200:
                        logger.error(f"í‘œì¤€ API í˜¸ì¶œ ì‹¤íŒ¨: {response.status}")
                        return results

                    data = await response.text()
                    logger.info(f"í‘œì¤€ API ì‘ë‹µ ë‚´ìš© (ì²˜ìŒ 300ì): {data[:300]}")

                    if not data.strip():
                        logger.warning("í‘œì¤€ APIì—ì„œ ë¹ˆ ì‘ë‹µ ìˆ˜ì‹ ")
                        return results

                    if data.strip().startswith('<OpenAPI_ServiceResponse>'):
                        logger.error("G2B í‘œì¤€ API ì¸ì¦ ì˜¤ë¥˜ - XML ì˜¤ë¥˜ ì‘ë‹µ ìˆ˜ì‹ ")
                        if 'SERVICE_ACCESS_DENIED_ERROR' in data and self.api_key:
                            masked_key = self._mask_api_key(self.api_key)
                            logger.error("ğŸš« G2B API í‚¤ ì¸ì¦ ì‹¤íŒ¨ (ì˜¤ë¥˜ì½”ë“œ: 20)")
                            logger.error("ğŸ“‹ í•´ê²° ë°©ë²•:")
                            logger.error("   1. data.go.kr ê³µê³µë°ì´í„°í¬í„¸ ì ‘ì†")
                            logger.error("   2. 'ë‚˜ë¼ì¥í„° ê³µê³µë°ì´í„°ê°œë°©í‘œì¤€ì„œë¹„ìŠ¤' ê²€ìƒ‰ ë° í™œìš©ì‹ ì²­")
                            logger.error("   3. ìŠ¹ì¸ëœ API í‚¤ë¥¼ .env íŒŒì¼ì˜ G2B_API_KEYì— ì„¤ì •")
                            logger.error(f"   4. í˜„ì¬ ì„¤ì •ëœ í‚¤: {masked_key}")
                        logger.error(f"ğŸ“„ ì „ì²´ ì˜¤ë¥˜ ì‘ë‹µ: {data}")
                        return results

                    try:
                        json_data = json.loads(data)
                        logger.info(
                            "í‘œì¤€ API JSON íŒŒì‹± ì„±ê³µ. ì‘ë‹µ êµ¬ì¡°: "
                            f"{list(json_data.keys()) if isinstance(json_data, dict) else type(json_data)}"
                        )
                    except json.JSONDecodeError as e:
                        logger.error(f"í‘œì¤€ API JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        logger.error(f"ì‘ë‹µ ë‚´ìš©: {data}")
                        return results

                    results = await self._parse_standard_api_response(json_data, keywords)

        except Exception as e:
            logger.error(f"í‘œì¤€ API ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")

        return results

    async def _parse_api_response(
        self,
        json_data: Dict[str, Any],
        category: str,
        keywords: List[str],
        display_name: Optional[str] = None,
    ) -> List[Dict[str, Any]]:
        """BidPublicInfoService API ì‘ë‹µ ë°ì´í„° íŒŒì‹±"""
        results: List[Dict[str, Any]] = []
        category_label = display_name or category

        try:
            if 'response' not in json_data:
                logger.warning("API ì‘ë‹µì— 'response' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
                # ResponseError í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸
                if 'nkoneps.com.response.ResponseError' in json_data:
                    error_info = json_data['nkoneps.com.response.ResponseError']
                    error_header = error_info.get('header', {})
                    error_code = error_header.get('resultCode', '')
                    error_msg = error_header.get('resultMsg', '')
                    logger.error(f"G2B API ì˜¤ë¥˜ ë°œìƒ - ì½”ë“œ: {error_code}, ë©”ì‹œì§€: {error_msg}")

                    if error_code == '07':
                        logger.error("ì…ë ¥ë²”ìœ„ê°’ ì´ˆê³¼ ì—ëŸ¬ - API ìš”ì²­ íŒŒë¼ë¯¸í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”")
                        logger.error("í•´ê²° ë°©ë²•: 1) ê²€ìƒ‰ ê¸°ê°„ ë‹¨ì¶•, 2) í˜ì´ì§€ í¬ê¸° ê°ì†Œ, 3) íŒŒë¼ë¯¸í„° ê°’ ê²€ì¦")
                return results

            response = json_data['response']
            header = response.get('header', {})
            result_code = header.get('resultCode') or header.get('resultcode')
            if result_code != '00':
                logger.warning(f"API ì˜¤ë¥˜: {header.get('resultMsg', 'Unknown error')} (ì½”ë“œ: {result_code})")
                return results

            body = response.get('body', {})
            items = body.get('items', [])

            if not items:
                logger.info(f"ì¹´í…Œê³ ë¦¬ '{category_label}'ì—ì„œ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                return results

            # ì‹¤ì œ ë°˜í™˜ëœ ë°ì´í„° í™•ì¸ì„ ìœ„í•œ ë¡œê·¸
            logger.info(f"ğŸ“‹ {category_label} - APIì—ì„œ {len(items)}ê±´ì˜ ì…ì°° ë°ì´í„° ë°˜í™˜")
            if len(items) > 0:
                first_item = items[0]
                logger.info(f"ğŸ“„ ì²« ë²ˆì§¸ ì•„ì´í…œ ìƒ˜í”Œ: {first_item.get('bidNtceNm', first_item.get('ntceNm', 'ì œëª©ì—†ìŒ'))}")

            items = self._normalize_items(items)

            for item in items:
                try:
                    title = self._get_first_non_empty(item, ['bidNtceNm', 'ntceNm', 'bidNm'])
                    organization = self._get_first_non_empty(item, ['ntceInsttNm', 'dminsttNm', 'insttNm'])

                    # í‚¤ì›Œë“œ ê´€ë ¨ì„± í™•ì¸
                    if not self._is_keyword_relevant(title, organization, keywords):
                        continue

                    deadline_date = self._get_first_non_empty(item, ['bidClseDt', 'bidClseDt1', 'bidClseDt2'])
                    estimated_price_raw = self._get_first_non_empty(
                        item, ['presmptPrce', 'asignBdgtAmt', 'bdgtAmt', 'refAmt']
                    )

                    logger.info(f"ğŸ“ [{category_label}] {title[:80]}")
                    logger.info(f"    ğŸ¢ ë°œì£¼ê¸°ê´€: {organization}")
                    logger.info(f"    ğŸ’° ì¶”ì •ê°€ê²©: {self._format_price(estimated_price_raw)}")
                    logger.info(f"    ğŸ“… ë§ˆê°ì¼: {deadline_date}")

                    relevance_score = self.calculate_relevance_score(title, organization)
                    urgency_level = self.determine_urgency_level(deadline_date)

                    bid_number = item.get('bidNtceNo', '')
                    bid_notice_order = item.get('bidNtceOrd', '')
                    announcement_date_raw = self._get_first_non_empty(
                        item, ['bidNtceDt', 'rgstDt', 'ntceDt']
                    )
                    estimated_price_raw = self._get_first_non_empty(
                        item, ['presmptPrce', 'asignBdgtAmt', 'bdgtAmt', 'refAmt']
                    )
                    budget_amount_raw = self._get_first_non_empty(
                        item, ['asignBdgtAmt', 'bdgtAmt', 'presmptPrce']
                    )

                    detail_url = self._get_first_non_empty(item, ['bidNtceDtlUrl', 'bidNtceUrl']) or self._generate_detail_url(
                        bid_number,
                        bid_notice_order
                    )

                    bid_info = {
                        "title": title,
                        "organization": organization,
                        "bid_number": bid_number,
                        "announcement_date": self._format_date(announcement_date_raw),
                        "deadline_date": self._format_date(deadline_date),
                        "estimated_price": self._format_price(estimated_price_raw),
                        "currency": "KRW",
                        "source_url": detail_url,
                        "source_site": "G2B",
                        "country": "KR",
                        "keywords": self._extract_keywords(title, organization),
                        "relevance_score": relevance_score,
                        "urgency_level": urgency_level,
                        "status": "active",
                        "extra_data": {
                            "crawled_at": datetime.now().isoformat(),
                            "category": category,
                            "category_label": category_label,
                            "bid_method": item.get('bidMethdNm', ''),
                            "contract_method": self._get_first_non_empty(
                                item, ['cntrctCnclsMthdNm', 'cntrctMthdNm']
                            ),
                            "bid_qualification": self._get_first_non_empty(item, ['bidQlfctNm', 'bidPrtcptQlfctNm']),
                            "opening_date": self._format_date(self._get_first_non_empty(item, ['opengDt', 'bidOpenDt'])),
                            "opening_place": self._get_first_non_empty(item, ['opengPlce', 'bidOpenPlce']),
                            "contact_name": self._get_first_non_empty(item, ['ofclNm', 'chrgePerNm']),
                            "contact_phone": self._get_first_non_empty(item, ['ofclTelNo', 'chrgePerTel']),
                            "contact_email": self._get_first_non_empty(item, ['ofclEmail', 'chrgePerEmail']),
                            "reference_number": self._get_first_non_empty(item, ['refNo', 'bidNtceRefNo']),
                            "notice_division": self._get_first_non_empty(item, ['ntceDivNm', 'ntceKindNm']),
                            "vat_included": self._get_first_non_empty(item, ['vatInclsnYnNm', 'vatYnNm']),
                            "budget_amount": self._format_price(budget_amount_raw),
                            "region_limit": self._get_first_non_empty(item, ['rgnLmtDivNm', 'bidAreaLmtYnNm']),
                            "bid_notice_order": bid_notice_order,
                            "api_data": True,
                            "api_service": "BidPublicInfoService"
                        }
                    }

                    results.append(bid_info)

                except Exception as e:
                    logger.warning(f"[{category_label}] ê°œë³„ ì•„ì´í…œ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
                    continue

        except Exception as e:
            logger.error(f"[{category_label}] API ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")

        if results:
            logger.info(f"âœ… [{category_label}] ìˆ˜ì§‘ ì™„ë£Œ: {len(results)}ê±´")
        else:
            logger.info(f"âŒ [{category_label}] ìˆ˜ì§‘ ê²°ê³¼ ì—†ìŒ")

        return results

    async def _parse_standard_api_response(self, json_data: Dict[str, Any], keywords: List[str]) -> List[Dict[str, Any]]:
        """ê³µê³µë°ì´í„°ê°œë°©í‘œì¤€ì„œë¹„ìŠ¤ API ì‘ë‹µ ë°ì´í„° íŒŒì‹±"""
        results: List[Dict[str, Any]] = []

        try:
            if 'response' not in json_data:
                logger.warning("í‘œì¤€ API ì‘ë‹µì— 'response' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
                # ResponseError í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸
                if 'nkoneps.com.response.ResponseError' in json_data:
                    error_info = json_data['nkoneps.com.response.ResponseError']
                    error_header = error_info.get('header', {})
                    error_code = error_header.get('resultCode', '')
                    error_msg = error_header.get('resultMsg', '')
                    logger.error(f"í‘œì¤€ API ì˜¤ë¥˜ ë°œìƒ - ì½”ë“œ: {error_code}, ë©”ì‹œì§€: {error_msg}")

                    if error_code == '07':
                        logger.error("ì…ë ¥ë²”ìœ„ê°’ ì´ˆê³¼ ì—ëŸ¬ - API ìš”ì²­ íŒŒë¼ë¯¸í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”")
                        logger.error("í•´ê²° ë°©ë²•: 1) ê²€ìƒ‰ ê¸°ê°„ ë‹¨ì¶•, 2) í˜ì´ì§€ í¬ê¸° ê°ì†Œ, 3) íŒŒë¼ë¯¸í„° ê°’ ê²€ì¦")
                return results

            response = json_data['response']
            header = response.get('header', {})
            result_code = header.get('resultCode') or header.get('resultcode')
            if result_code != '00':
                logger.warning(f"í‘œì¤€ API ì˜¤ë¥˜: {header.get('resultMsg', 'Unknown error')} (ì½”ë“œ: {result_code})")
                return results

            body = response.get('body', {})
            items = body.get('items', [])
            total_count = body.get('totalCount', 0)

            logger.info(f"ğŸ“Š í‘œì¤€ API ì „ì²´ ê²°ê³¼ ìˆ˜: {total_count}ê±´")
            logger.info(f"ğŸ” items íƒ€ì…: {type(items)}, ê¸¸ì´: {len(items) if isinstance(items, list) else 'N/A'}")

            # ì‘ë‹µ êµ¬ì¡° ë””ë²„ê¹…
            if items and isinstance(items, list) and len(items) > 0:
                logger.info(f"ğŸ“„ ì²« ë²ˆì§¸ ì•„ì´í…œ ìƒ˜í”Œ í‚¤ë“¤: {list(items[0].keys())}")
                logger.info(f"ğŸ“„ ì²« ë²ˆì§¸ ì•„ì´í…œ ì „ì²´: {items[0]}")

            if not items:
                logger.info("í‘œì¤€ API ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                return results

            items = self._normalize_items(items)

            for idx, item in enumerate(items):
                try:
                    title = item.get('ntceNm', '')
                    organization = item.get('ntceInsttNm', '')

                    # logger.info(f"ğŸ“‹ í‘œì¤€ API ì…ì°°ì œëª©: {title}")  # ì¤‘ë³µ ë¡œê·¸ ì œê±°

                    # í‚¤ì›Œë“œ ê´€ë ¨ì„± í™•ì¸
                    if not self._is_keyword_relevant(title, organization, keywords):
                        continue

                    deadline_date = item.get('bidClseDate', '')
                    estimated_price = item.get('presmptPrce', '')

                    logger.info(f"ğŸ“ [{idx+1}] {title[:80]}")
                    logger.info(f"    ğŸ¢ ë°œì£¼ê¸°ê´€: {organization}")
                    logger.info(f"    ğŸ’° ì¶”ì •ê°€ê²©: {self._format_price(estimated_price)}")
                    logger.info(f"    ğŸ“… ë§ˆê°ì¼: {deadline_date}")

                    relevance_score = self.calculate_relevance_score(title, organization)
                    urgency_level = self.determine_urgency_level(deadline_date)

                    bid_number = item.get('bidNtceNo', '')
                    bid_notice_order = item.get('bidNtceOrd', '')

                    bid_info = {
                        "title": title,
                        "organization": organization,
                        "bid_number": bid_number,
                        "announcement_date": self._format_date(item.get('nticeDt', '')),
                        "deadline_date": self._format_date(deadline_date),
                        "estimated_price": self._format_price(item.get('presmptPrce', '')),
                        "currency": "KRW",
                        "source_url": item.get('bidNtceUrl', ''),
                        "source_site": "G2B",
                        "country": "KR",
                        "keywords": self._extract_keywords(title, organization),
                        "relevance_score": relevance_score,
                        "urgency_level": urgency_level,
                        "status": "active",
                        "extra_data": {
                            "crawled_at": datetime.now().isoformat(),
                            "bid_notice_order": bid_notice_order,
                            "business_division": item.get('bsnsDivNm', ''),
                            "contract_method": item.get('cntrctCnclsMthdNm', ''),
                            "contract_type": item.get('cntrctCnclsSttusNm', ''),
                            "decision_method": item.get('bidwinrDcsnMthdNm', ''),
                            "opening_date": self._format_date(item.get('opengDate', '')),
                            "opening_time": item.get('opengTm', ''),
                            "opening_place": item.get('opengPlce', ''),
                            "budget_amount": self._format_price(item.get('asignBdgtAmt', '')),
                            "international_bid": item.get('intrntnlBidYn', ''),
                            "electronic_bid": item.get('elctrnBidYn', ''),
                            "demand_institution": item.get('dmndInsttNm', ''),
                            "notice_status": item.get('bidNtceSttusNm', ''),
                            "region_limit": item.get('rgnLmtYn', ''),
                            "industry_limit": item.get('indstrytyLmtYn', ''),
                            "api_data": True,
                            "api_service": "OpenDataStandard"
                        }
                    }

                    results.append(bid_info)

                except Exception as e:
                    logger.warning(f"í‘œì¤€ API ê°œë³„ ì•„ì´í…œ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
                    continue

        except Exception as e:
            logger.error(f"í‘œì¤€ API ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")

        if results:
            logger.info(f"âœ… [í‘œì¤€ API] ìˆ˜ì§‘ ì™„ë£Œ: {len(results)}ê±´")
        else:
            logger.info(f"âŒ [í‘œì¤€ API] ìˆ˜ì§‘ ê²°ê³¼ ì—†ìŒ")

        return results

    def _extract_total_count(self, json_data: Dict[str, Any]) -> Optional[int]:
        """ì‘ë‹µì—ì„œ totalCount ê°’ì„ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ"""
        try:
            body = json_data.get("response", {}).get("body", {})
            total = body.get("totalCount")
            if total is None or total == "":
                return None
            return int(total)
        except (ValueError, TypeError, AttributeError):
            return None

    def _matches_keywords(self, title: str, organization: str, keywords: List[str]) -> bool:
        """í‚¤ì›Œë“œ ë§¤ì¹­ í™•ì¸"""
        from src.config import crawler_config

        text = f"{title} {organization}".lower()

        all_keywords: List[str] = []
        all_keywords.extend(crawler_config.SEEGENE_KEYWORDS['korean'])
        all_keywords.extend(crawler_config.SEEGENE_KEYWORDS['english'])

        for keyword in all_keywords:
            if keyword.lower() in text:
                return True

        for keyword in keywords:
            if keyword.lower() in text:
                return True

        return False

    def _extract_keywords(self, title: str, organization: str = "") -> List[str]:
        """ì œëª©ê³¼ ê¸°ê´€ëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords: List[str] = []
        text_lower = f"{title} {organization}".lower()

        from src.config import crawler_config
        for keyword in crawler_config.SEEGENE_KEYWORDS['korean']:
            if keyword.lower() in text_lower:
                keywords.append(keyword)
        for keyword in crawler_config.SEEGENE_KEYWORDS['english']:
            if keyword.lower() in text_lower:
                keywords.append(keyword)

        return list(set(keywords))

    def _normalize_items(self, items: Any) -> List[Dict[str, Any]]:
        """API ì‘ë‹µ items êµ¬ì¡°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ê·œí™”"""
        if isinstance(items, list):
            return [item for item in items if isinstance(item, dict)]

        if isinstance(items, dict):
            if 'item' in items:
                nested = items['item']
                if isinstance(nested, list):
                    return [item for item in nested if isinstance(item, dict)]
                if isinstance(nested, dict):
                    return [nested]
            return [items]

        return []

    def _get_first_non_empty(self, item: Dict[str, Any], keys: List[str]) -> str:
        """ì£¼ì–´ì§„ í‚¤ ëª©ë¡ì—ì„œ ê°€ì¥ ë¨¼ì € ë“±ì¥í•˜ëŠ” ìœ íš¨í•œ ê°’ì„ ë°˜í™˜"""
        for key in keys:
            value = item.get(key)
            if value is not None and str(value).strip() != "":
                return value
        return ""

    def _format_date(self, date_str: str) -> str:
        """ë‚ ì§œ í˜•ì‹ ë³€í™˜"""
        if not date_str:
            return ""

        value = str(date_str).strip()
        if not value:
            return ""

        date_formats = [
            "%Y-%m-%d %H:%M:%S",
            "%Y-%m-%d %H:%M",
            "%Y-%m-%d",
            "%Y%m%d%H%M%S",
            "%Y%m%d%H%M",
            "%Y%m%d",
            "%Y/%m/%d",
            "%Y.%m.%d"
        ]

        for fmt in date_formats:
            try:
                parsed_date = datetime.strptime(value, fmt)
                return parsed_date.strftime("%Y-%m-%d")
            except ValueError:
                continue

        if len(value) >= 10:
            return value[:10]
        return value

    def _format_price(self, price_str: str) -> str:
        """ê°€ê²© í˜•ì‹ ë³€í™˜"""
        if price_str is None:
            return ""

        value = str(price_str).strip()
        if not value:
            return ""

        normalized = value.replace(",", "")

        try:
            price_num = float(normalized)
        except ValueError:
            filtered = "".join(ch for ch in normalized if ch.isdigit() or ch == '.')
            if not filtered:
                return value
            try:
                price_num = float(filtered)
            except ValueError:
                return value

        return f"{int(price_num):,}ì›"

    def _generate_detail_url(self, bid_number: str, bid_notice_order: str = "") -> str:
        """ìƒì„¸ í˜ì´ì§€ URL ìƒì„±"""
        if not bid_number:
            return ""
        base_url = "https://www.g2b.go.kr/ep/invitation/publish/bidInfoDtl/bidInfoDtl.do"
        if bid_notice_order:
            return f"{base_url}?bidNo={bid_number}&bidRound={bid_notice_order}"
        return f"{base_url}?bidNo={bid_number}"

    def _remove_duplicates(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì¤‘ë³µ ì œê±°"""
        seen_bid_keys = set()
        unique_results: List[Dict[str, Any]] = []

        for result in results:
            bid_number = result.get('bid_number', '')
            bid_notice_order = ''
            extra_data = result.get('extra_data')
            if isinstance(extra_data, dict):
                bid_notice_order = extra_data.get('bid_notice_order', '')
            bid_key = (bid_number, bid_notice_order)

            if bid_number and bid_key not in seen_bid_keys:
                seen_bid_keys.add(bid_key)
                unique_results.append(result)
            elif not bid_number:
                source_url = result.get('source_url', '')
                if source_url not in [r.get('source_url', '') for r in unique_results]:
                    unique_results.append(result)

        return unique_results

    def parse_deadline(self, deadline_str: str) -> Optional[datetime]:
        """G2B API ë§ˆê°ì¼ íŒŒì‹±"""
        try:
            if not deadline_str or deadline_str.strip() == "":
                return None

            for fmt in ["%Y-%m-%d %H:%M:%S", "%Y-%m-%d", "%Y/%m/%d", "%Y.%m.%d"]:
                try:
                    return datetime.strptime(deadline_str.strip(), fmt)
                except ValueError:
                    continue

            return None

        except Exception:
            return None


    def _prepare_service_key(self, api_key: Optional[str]) -> Optional[str]:
        """ìš”ì²­ì— ì‚¬ìš©í•  ì„œë¹„ìŠ¤ í‚¤ë¥¼ ì „ì²˜ë¦¬"""
        if not api_key:
            return None

        key = api_key.strip()
        if not key:
            return None

        # ì´ë¯¸ ì¸ì½”ë”©ëœ ê²½ìš°(%)ëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
        if "%" in key:
            return key

        try:
            return quote(key, safe="")
        except Exception:
            return key

    def _mask_api_key(self, api_key: str) -> str:
        """API í‚¤ ë§ˆìŠ¤í‚¹"""
        if len(api_key) <= 8:
            return api_key
        return f"{api_key[:4]}...{api_key[-4:]}"

    def _is_keyword_relevant(self, title: str, organization: str, keywords: List[str]) -> bool:
        """í‚¤ì›Œë“œì™€ ê´€ë ¨ì„±ì´ ìˆëŠ”ì§€ í™•ì¸"""
        if not keywords:
            return True  # í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ëª¨ë“  ê²°ê³¼ í¬í•¨

        text = f"{title} {organization}".lower()

        # ì œê³µëœ í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ê´€ë ¨ì„± ìˆìŒ
        for keyword in keywords:
            if keyword.lower() in text:
                return True

        return False
