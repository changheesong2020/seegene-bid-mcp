"""
G2B (ë‚˜ë¼ì¥í„°) API Crawler
ì¡°ë‹¬ì²­ ê³µê³µë°ì´í„° í¬í„¸ Open API - ì…ì°°ê³µê³ ì •ë³´ì„œë¹„ìŠ¤ ê¸°ë°˜ í¬ë¡¤ëŸ¬
"""

import asyncio
import aiohttp
import json
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional

from src.crawler.base import BaseCrawler
from src.config import settings
from src.utils.logger import get_logger

logger = get_logger(__name__)


class G2BCrawler(BaseCrawler):
    """ë‚˜ë¼ì¥í„°(G2B) API í¬ë¡¤ëŸ¬"""

    def __init__(self):
        super().__init__("G2B", "KR")
<<<<<<< HEAD
        self.api_base_url = "http://apis.data.go.kr/1230000/ao/PubDataOpnStdService"
        self.api_key = settings.G2B_API_KEY

        # ê³µê³µë°ì´í„°ê°œë°©í‘œì¤€ì„œë¹„ìŠ¤ ì˜¤í¼ë ˆì´ì…˜
        self.operation = "getDataSetOpnStdBidPblancInfo"  # ì…ì°°ê³µê³ ì •ë³´
=======
        self.api_base_url = "https://apis.data.go.kr/1230000/ad/BidPublicInfoService"
        self.api_key = settings.G2B_API_KEY

        # API ì˜¤í¼ë ˆì´ì…˜ ì—”ë“œí¬ì¸íŠ¸
        self.operations = {
            "service": "getBidPblancListInfoServc",      # ìš©ì—­
            "goods": "getBidPblancListInfoThng",         # ë¬¼í’ˆ
            "construction": "getBidPblancListInfoCnstwk", # ê³µì‚¬
            "etc": "getBidPblancListInfoEtc"             # ê¸°íƒ€
        }
>>>>>>> 4c7bf815c6480e85632e520778aff85a1437ef68

    async def login(self) -> bool:
        """API ê¸°ë°˜ì´ë¯€ë¡œ ë¡œê·¸ì¸ ë¶ˆí•„ìš”"""
        if not self.api_key:
            logger.warning("G2B API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            logger.warning("data.go.krì—ì„œ 'ëˆ„ë¦¬ì¥í„° ë¯¼ê°„ì…ì°°ê³µê³ ì„œë¹„ìŠ¤' API í‚¤ë¥¼ ë°œê¸‰ë°›ì•„ .env íŒŒì¼ì˜ G2B_API_KEYì— ì„¤ì •í•˜ì„¸ìš”.")
            logger.warning("ë”ë¯¸ ëª¨ë“œë¡œ ì „í™˜ë©ë‹ˆë‹¤.")
            self.dummy_mode = True
            return False

        logger.info("G2B API í‚¤ ì¸ì¦ ì¤€ë¹„ ì™„ë£Œ")
        return True

    def setup_driver(self):
        """API ê¸°ë°˜ì´ë¯€ë¡œ WebDriver ë¶ˆí•„ìš”"""
        logger.info("G2B API í¬ë¡¤ëŸ¬ - WebDriver ì„¤ì • ìŠ¤í‚µ")
        self.dummy_mode = not bool(self.api_key)

    def teardown_driver(self):
        """API ê¸°ë°˜ì´ë¯€ë¡œ ì •ë¦¬ ì‘ì—… ë¶ˆí•„ìš”"""
        logger.info("G2B API í¬ë¡¤ëŸ¬ - WebDriver ì •ë¦¬ ìŠ¤í‚µ")

    async def search_bids(self, keywords: List[str]) -> List[Dict[str, Any]]:
        """ì…ì°° ì •ë³´ ê²€ìƒ‰"""
        if self.dummy_mode:
            logger.info("G2B API í‚¤ê°€ ì—†ì–´ ë”ë¯¸ ëª¨ë“œë¡œ ì‹¤í–‰")
            dummy_data = self.generate_dummy_data(keywords)
            # ë”ë¯¸ ë°ì´í„°ë„ ê²°ê³¼ì— í¬í•¨ì‹œì¼œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•˜ë„ë¡
            await self._save_dummy_results(dummy_data)
            return dummy_data

        all_results = []

        try:
            # Seegene í‚¤ì›Œë“œ ì¶”ê°€
            from src.config import crawler_config
            seegene_keywords = []
            seegene_keywords.extend(crawler_config.SEEGENE_KEYWORDS['korean'][:3])  # ìƒìœ„ 3ê°œ í•œêµ­ì–´ í‚¤ì›Œë“œ
            seegene_keywords.extend(crawler_config.SEEGENE_KEYWORDS['english'][:3])  # ìƒìœ„ 3ê°œ ì˜ì–´ í‚¤ì›Œë“œ

            # ì‚¬ìš©ì í‚¤ì›Œë“œì™€ Seegene í‚¤ì›Œë“œ ê²°í•©
            search_keywords = keywords + seegene_keywords
            logger.info(f"ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ: {search_keywords}")

            # ê³µê³µë°ì´í„°ê°œë°©í‘œì¤€ì„œë¹„ìŠ¤ API ê²€ìƒ‰
            results = await self._search_standard_api(search_keywords)
            all_results.extend(results)

            # ì¤‘ë³µ ì œê±°
            unique_results = self._remove_duplicates(all_results)

            logger.info(f"G2B API ê²€ìƒ‰ ì™„ë£Œ: ì´ {len(unique_results)}ê±´")
            return unique_results

        except Exception as e:
            logger.error(f"G2B API ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return all_results

    async def _search_standard_api(self, keywords: List[str]) -> List[Dict[str, Any]]:
        """ê³µê³µë°ì´í„°ê°œë°©í‘œì¤€ì„œë¹„ìŠ¤ API ê²€ìƒ‰"""
        results = []

        try:
            # ê²€ìƒ‰ ê¸°ê°„ ì„¤ì • (ìµœê·¼ 30ì¼, API ì œí•œ: 1ê°œì›”)
            end_date = datetime.now()
            start_date = end_date - timedelta(days=30)

            # í‘œì¤€ API íŒŒë¼ë¯¸í„° êµ¬ì„±
            params = {
                'ServiceKey': self.api_key,  # ëŒ€ë¬¸ì S ì£¼ì˜
                'type': 'json',
                'numOfRows': 100,
                'pageNo': 1,
                'bidNtceBgnDt': start_date.strftime('%Y%m%d%H%M'),  # ì…ì°°ê³µê³ ì‹œì‘ì¼ì‹œ
                'bidNtceEndDt': end_date.strftime('%Y%m%d%H%M')     # ì…ì°°ê³µê³ ì¢…ë£Œì¼ì‹œ
            }

            logger.info(f"ğŸ” í‘œì¤€ API ê²€ìƒ‰ - ê¸°ê°„: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}")

            # API í˜¸ì¶œ
            async with aiohttp.ClientSession() as session:
                url = f"{self.api_base_url}/{self.operation}"

                async with session.get(url, params=params) as response:
                    if response.status != 200:
                        logger.error(f"API í˜¸ì¶œ ì‹¤íŒ¨: {response.status}")
                        return results

                    data = await response.text()
<<<<<<< HEAD
                    logger.info(f"API ì‘ë‹µ ë‚´ìš© (ì²˜ìŒ 500ì): {data[:500]}")

                    if not data.strip():
                        logger.warning("APIì—ì„œ ë¹ˆ ì‘ë‹µ ìˆ˜ì‹ ")
                        return results

                    # XML ì˜¤ë¥˜ ì‘ë‹µ í™•ì¸
                    if data.strip().startswith('<OpenAPI_ServiceResponse>'):
                        logger.error("G2B API ì¸ì¦ ì˜¤ë¥˜ - XML ì˜¤ë¥˜ ì‘ë‹µ ìˆ˜ì‹ ")
                        if 'SERVICE_ACCESS_DENIED_ERROR' in data:
                            logger.error("ğŸš« G2B API í‚¤ ì¸ì¦ ì‹¤íŒ¨ (ì˜¤ë¥˜ì½”ë“œ: 20)")
                            logger.error("ğŸ“‹ í•´ê²° ë°©ë²•:")
                            logger.error("   1. data.go.kr ê³µê³µë°ì´í„°í¬í„¸ ì ‘ì†")
                            logger.error("   2. 'ë‚˜ë¼ì¥í„° ê³µê³µë°ì´í„°ê°œë°©í‘œì¤€ì„œë¹„ìŠ¤' ê²€ìƒ‰ ë° í™œìš©ì‹ ì²­")
                            logger.error("   3. ìŠ¹ì¸ëœ API í‚¤ë¥¼ .env íŒŒì¼ì˜ G2B_API_KEYì— ì„¤ì •")
                            logger.error(f"   4. í˜„ì¬ ì„¤ì •ëœ í‚¤: {self.api_key[:10]}...{self.api_key[-10:]}")
                        logger.error(f"ğŸ“„ ì „ì²´ ì˜¤ë¥˜ ì‘ë‹µ: {data}")
                        return results

                    try:
                        json_data = json.loads(data)
                        logger.info(f"JSON íŒŒì‹± ì„±ê³µ. ì‘ë‹µ êµ¬ì¡°: {list(json_data.keys()) if isinstance(json_data, dict) else type(json_data)}")
                    except json.JSONDecodeError as e:
                        logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        logger.error(f"ì‘ë‹µ ë‚´ìš©: {data}")
=======
                    try:
                        json_data = json.loads(data)
                    except json.JSONDecodeError:
                        logger.error("API ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. XML ì‘ë‹µì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
>>>>>>> 4c7bf815c6480e85632e520778aff85a1437ef68
                        return results

                    # ì‘ë‹µ ë°ì´í„° íŒŒì‹±
                    results = await self._parse_standard_api_response(json_data, keywords)

        except Exception as e:
            logger.error(f"í‘œì¤€ API ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")

        return results

    async def _parse_standard_api_response(self, json_data: Dict, keywords: List[str]) -> List[Dict[str, Any]]:
        """API ì‘ë‹µ ë°ì´í„° íŒŒì‹±"""
        results = []

        try:
            # í‘œì¤€ API ì‘ë‹µ êµ¬ì¡° í™•ì¸
            if 'response' not in json_data:
                logger.warning("API ì‘ë‹µì— 'response' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
                return results

            response = json_data['response']

            # ê²°ê³¼ ì½”ë“œ í™•ì¸
            header = response.get('header', {})
            result_code = header.get('resultCode') or header.get('resultcode')
            if result_code != '00':
                logger.warning(f"API ì˜¤ë¥˜: {header.get('resultMsg', 'Unknown error')}")
                return results

            # ë°ì´í„° ì¶”ì¶œ
            body = response.get('body', {})
            items = body.get('items', [])
            total_count = body.get('totalCount', 0)

            logger.info(f"ğŸ“Š ì „ì²´ ê²°ê³¼ ìˆ˜: {total_count}ê±´")
            logger.info(f"ğŸ” items íƒ€ì…: {type(items)}, ê¸¸ì´: {len(items) if isinstance(items, list) else 'N/A'}")

            if not items:
                logger.info("ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                return results

            # ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬ (ë‹¨ì¼ ì•„ì´í…œì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜)
            items = self._normalize_items(items)

            for item in items:
                try:
<<<<<<< HEAD
                    # í‚¤ì›Œë“œ í•„í„°ë§ (í‘œì¤€ API í•„ë“œ ì‚¬ìš©)
                    title = item.get('ntceNm', '')  # ì…ì°°ê³µê³ ëª…
                    organization = item.get('ntceInsttNm', '')  # ê³µê³ ê¸°ê´€ëª…

                    # ë””ë²„ê¹…: ì…ì°° ì œëª© ë¡œê·¸
                    logger.info(f"ğŸ“‹ ì…ì°°ì œëª©: {title}")
=======
                    # í‚¤ì›Œë“œ í•„í„°ë§
                    title = self._get_first_non_empty(item, ['bidNtceNm', 'ntceNm', 'bidNm'])
                    organization = self._get_first_non_empty(item, ['ntceInsttNm', 'dminsttNm', 'insttNm'])
>>>>>>> 4c7bf815c6480e85632e520778aff85a1437ef68

                    if not self._matches_keywords(title, organization, keywords):
                        logger.info(f"âŒ í‚¤ì›Œë“œ ë§¤ì¹­ ì‹¤íŒ¨: {title[:50]}...")
                        continue

                    logger.info(f"âœ… í‚¤ì›Œë“œ ë§¤ì¹­ ì„±ê³µ: {title[:50]}...")

                    # ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
                    relevance_score = self.calculate_relevance_score(title, organization)

                    # ê¸´ê¸‰ë„ ë ˆë²¨ ê³„ì‚°
<<<<<<< HEAD
                    deadline_date = item.get('bidClseDate', '')  # ì…ì°°ë§ˆê°ì¼ì
                    urgency_level = self.determine_urgency_level(deadline_date)

                    # ì…ì°°ì •ë³´ êµ¬ì„± (í‘œì¤€ API í•„ë“œ ë§¤í•‘)
                    bid_info = {
                        "title": title,
                        "organization": organization,
                        "bid_number": item.get('bidNtceNo', ''),  # ì…ì°°ê³µê³ ë²ˆí˜¸
                        "announcement_date": item.get('nticeDt', ''),  # ì…ì°°ê³µê³ ì¼ì
                        "deadline_date": deadline_date,
                        "estimated_price": self._format_price(item.get('presmptPrce', '')),  # ì¶”ì •ê°€ê²©
                        "currency": "KRW",
                        "source_url": item.get('bidNtceUrl', ''),  # ì…ì°°ê³µê³ URL
=======
                    deadline_date = self._get_first_non_empty(item, ['bidClseDt', 'bidClseDt1', 'bidClseDt2'])
                    urgency_level = self.determine_urgency_level(deadline_date)

                    # ì…ì°°ì •ë³´ êµ¬ì„±
                    bid_number = item.get('bidNtceNo', '')
                    bid_notice_order = item.get('bidNtceOrd', '')
                    announcement_date_raw = self._get_first_non_empty(item, ['bidNtceDt', 'nticeDt', 'ntceDt'])
                    estimated_price_raw = self._get_first_non_empty(item, ['presmptPrce', 'refAmt', 'asignBdgtAmt'])
                    budget_amount_raw = self._get_first_non_empty(item, ['asignBdgtAmt', 'bdgtAmt'])

                    detail_url = self._get_first_non_empty(item, ['bidNtceDtlUrl']) or self._generate_detail_url(
                        bid_number,
                        bid_notice_order
                    )

                    bid_info = {
                        "title": title,
                        "organization": organization,
                        "bid_number": bid_number,
                        "announcement_date": self._format_date(announcement_date_raw),
                        "deadline_date": self._format_date(deadline_date),
                        "estimated_price": self._format_price(estimated_price_raw),
                        "currency": "KRW",
                        "source_url": detail_url,
>>>>>>> 4c7bf815c6480e85632e520778aff85a1437ef68
                        "source_site": "G2B",
                        "country": "KR",
                        "keywords": self._extract_keywords(title, organization),
                        "relevance_score": relevance_score,
                        "urgency_level": urgency_level,
                        "status": "active",
                        "extra_data": {
                            "crawled_at": datetime.now().isoformat(),
<<<<<<< HEAD
                            "bid_order": item.get('bidNtceOrd', ''),  # ì…ì°°ê³µê³ ì°¨ìˆ˜
                            "business_division": item.get('bsnsDivNm', ''),  # ì—…ë¬´êµ¬ë¶„ëª…
                            "contract_method": item.get('cntrctCnclsMthdNm', ''),  # ê³„ì•½ì²´ê²°ë°©ë²•ëª…
                            "contract_type": item.get('cntrctCnclsSttusNm', ''),  # ê³„ì•½ì²´ê²°í˜•íƒœëª…
                            "decision_method": item.get('bidwinrDcsnMthdNm', ''),  # ë‚™ì°°ìê²°ì •ë°©ë²•ëª…
                            "opening_date": item.get('opengDate', ''),  # ê°œì°°ì¼ì
                            "opening_time": item.get('opengTm', ''),  # ê°œì°°ì‹œê°
                            "opening_place": item.get('opengPlce', ''),  # ê°œì°°ì¥ì†Œ
                            "budget_amount": self._format_price(item.get('asignBdgtAmt', '')),  # ë°°ì •ì˜ˆì‚°ê¸ˆì•¡
                            "international_bid": item.get('intrntnlBidYn', ''),  # êµ­ì œì…ì°°ì—¬ë¶€
                            "electronic_bid": item.get('elctrnBidYn', ''),  # ì „ìì…ì°°ì—¬ë¶€
                            "demand_institution": item.get('dmndInsttNm', ''),  # ìˆ˜ìš”ê¸°ê´€ëª…
                            "notice_status": item.get('bidNtceSttusNm', ''),  # ì…ì°°ê³µê³ ìƒíƒœëª…
                            "region_limit": item.get('rgnLmtYn', ''),  # ì§€ì—­ì œí•œì—¬ë¶€
                            "industry_limit": item.get('indstrytyLmtYn', ''),  # ì—…ì¢…ì œí•œì—¬ë¶€
                            "api_data": True,
                            "api_version": "standard"
=======
                            "category": category,
                            "bid_method": item.get('bidMethdNm', ''),
                            "contract_method": item.get('cntrctMthdNm', ''),
                            "bid_qualification": self._get_first_non_empty(item, ['bidQlfctNm', 'bidPrtcptQlfctNm']),
                            "opening_date": self._format_date(self._get_first_non_empty(item, ['opengDt', 'bidOpenDt'])),
                            "opening_place": self._get_first_non_empty(item, ['opengPlce', 'bidOpenPlce']),
                            "contact_name": self._get_first_non_empty(item, ['ofclNm', 'chrgePerNm']),
                            "contact_phone": self._get_first_non_empty(item, ['ofclTelNo', 'chrgePerTel']),
                            "contact_email": self._get_first_non_empty(item, ['ofclEmail', 'chrgePerEmail']),
                            "reference_number": self._get_first_non_empty(item, ['refNo', 'bidNtceRefNo']),
                            "notice_division": self._get_first_non_empty(item, ['ntceDivNm', 'ntceKindNm']),
                            "vat_included": self._get_first_non_empty(item, ['vatInclsnYnNm', 'vatYnNm']),
                            "budget_amount": self._format_price(budget_amount_raw),
                            "region_limit": self._get_first_non_empty(item, ['rgnLmtDivNm', 'bidAreaLmtYnNm']),
                            "bid_notice_order": bid_notice_order,
                            "api_data": True,
                            "api_service": "BidPublicInfoService"
>>>>>>> 4c7bf815c6480e85632e520778aff85a1437ef68
                        }
                    }

                    results.append(bid_info)

                except Exception as e:
                    logger.warning(f"ê°œë³„ ì•„ì´í…œ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
                    continue

        except Exception as e:
            logger.error(f"API ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")

        return results

    def _matches_keywords(self, title: str, organization: str, keywords: List[str]) -> bool:
        """í‚¤ì›Œë“œ ë§¤ì¹­ í™•ì¸"""
        from src.config import crawler_config

        text = f"{title} {organization}".lower()

        # Seegene í‚¤ì›Œë“œ í™•ì¸
        all_keywords = []
        all_keywords.extend(crawler_config.SEEGENE_KEYWORDS['korean'])
        all_keywords.extend(crawler_config.SEEGENE_KEYWORDS['english'])

        for keyword in all_keywords:
            if keyword.lower() in text:
                return True

        # ê²€ìƒ‰ í‚¤ì›Œë“œ í™•ì¸
        for keyword in keywords:
            if keyword.lower() in text:
                return True

        return False

    def _extract_keywords(self, title: str, organization: str = "") -> List[str]:
        """ì œëª©ê³¼ ê¸°ê´€ëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = []
        text_lower = f"{title} {organization}".lower()

        from src.config import crawler_config
        for keyword in crawler_config.SEEGENE_KEYWORDS['korean']:
            if keyword.lower() in text_lower:
                keywords.append(keyword)
        for keyword in crawler_config.SEEGENE_KEYWORDS['english']:
            if keyword.lower() in text_lower:
                keywords.append(keyword)

        return list(set(keywords))  # ì¤‘ë³µ ì œê±°

    def _normalize_items(self, items: Any) -> List[Dict[str, Any]]:
        """API ì‘ë‹µ items êµ¬ì¡°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ê·œí™”"""
        if isinstance(items, list):
            return [item for item in items if isinstance(item, dict)]

        if isinstance(items, dict):
            if 'item' in items:
                nested = items['item']
                if isinstance(nested, list):
                    return [item for item in nested if isinstance(item, dict)]
                if isinstance(nested, dict):
                    return [nested]
            return [items]

        return []

    def _get_first_non_empty(self, item: Dict[str, Any], keys: List[str]) -> str:
        """ì£¼ì–´ì§„ í‚¤ ëª©ë¡ì—ì„œ ê°€ì¥ ë¨¼ì € ë“±ì¥í•˜ëŠ” ìœ íš¨í•œ ê°’ì„ ë°˜í™˜"""
        for key in keys:
            value = item.get(key)
            if value is not None and str(value).strip() != "":
                return value
        return ""

    def _format_date(self, date_str: str) -> str:
        """ë‚ ì§œ í˜•ì‹ ë³€í™˜"""
        if not date_str:
            return ""

        value = str(date_str).strip()
        if not value:
            return ""

        date_formats = [
            "%Y-%m-%d %H:%M:%S",
            "%Y-%m-%d %H:%M",
            "%Y-%m-%d",
            "%Y%m%d%H%M%S",
            "%Y%m%d%H%M",
            "%Y%m%d",
            "%Y/%m/%d",
            "%Y.%m.%d"
        ]

        for fmt in date_formats:
            try:
                parsed_date = datetime.strptime(value, fmt)
                return parsed_date.strftime("%Y-%m-%d")
            except ValueError:
                continue

        if len(value) >= 10:
            return value[:10]
        return value

    def _format_price(self, price_str: str) -> str:
        """ê°€ê²© í˜•ì‹ ë³€í™˜"""
        if price_str is None:
            return ""

        value = str(price_str).strip()
        if not value:
            return ""

        normalized = value.replace(",", "")

        try:
            price_num = float(normalized)
        except ValueError:
            filtered = "".join(ch for ch in normalized if ch.isdigit() or ch == '.')
            if not filtered:
                return value
            try:
                price_num = float(filtered)
            except ValueError:
                return value

        return f"{int(price_num):,}ì›"

    def _generate_detail_url(self, bid_number: str, bid_notice_order: str = "") -> str:
        """ìƒì„¸ í˜ì´ì§€ URL ìƒì„±"""
        if not bid_number:
            return ""
        base_url = "https://www.g2b.go.kr/ep/invitation/publish/bidInfoDtl/bidInfoDtl.do"
        if bid_notice_order:
            return f"{base_url}?bidNo={bid_number}&bidRound={bid_notice_order}"
        return f"{base_url}?bidNo={bid_number}"

    def _remove_duplicates(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì¤‘ë³µ ì œê±°"""
        seen_bid_keys = set()
        unique_results = []

        for result in results:
            bid_number = result.get('bid_number', '')
            bid_notice_order = result.get('extra_data', {}).get('bid_notice_order', '') if isinstance(result.get('extra_data'), dict) else ''
            bid_key = (bid_number, bid_notice_order)

            if bid_number and bid_key not in seen_bid_keys:
                seen_bid_keys.add(bid_key)
                unique_results.append(result)
            elif not bid_number:  # bid_numberê°€ ì—†ëŠ” ê²½ìš° URLë¡œ ì¤‘ë³µ ì²´í¬
                source_url = result.get('source_url', '')
                if source_url not in [r.get('source_url', '') for r in unique_results]:
                    unique_results.append(result)

        return unique_results

    def parse_deadline(self, deadline_str: str) -> Optional[datetime]:
        """G2B API ë§ˆê°ì¼ íŒŒì‹±"""
        try:
            if not deadline_str or deadline_str.strip() == "":
                return None

            # API ì‘ë‹µ í˜•ì‹: "2025-01-15 14:30:00"
            for fmt in ["%Y-%m-%d %H:%M:%S", "%Y-%m-%d", "%Y/%m/%d", "%Y.%m.%d"]:
                try:
                    return datetime.strptime(deadline_str.strip(), fmt)
                except ValueError:
                    continue

            return None

        except Exception:
            return None

    def generate_dummy_data(self, keywords: List[str]) -> List[Dict[str, Any]]:
        """ë”ë¯¸ ë°ì´í„° ìƒì„± (API í‚¤ê°€ ì—†ì„ ë•Œ)"""
        dummy_bids = []

        categories = ["ìš©ì—­", "ë¬¼í’ˆ", "ê³µì‚¬", "ê¸°íƒ€"]

        for i, keyword in enumerate(keywords[:2]):  # ìµœëŒ€ 2ê°œ í‚¤ì›Œë“œ
            for j, category in enumerate(categories):
                dummy_bid = {
                    "title": f"[API í…ŒìŠ¤íŠ¸] {keyword} ê´€ë ¨ {category} ì…ì°°ê³µê³  {i+1}-{j+1}",
                    "organization": f"í…ŒìŠ¤íŠ¸ê¸°ê´€{i+1}-{j+1}",
                    "bid_number": f"API-TEST-{datetime.now().strftime('%Y%m%d')}-{i+1:02d}{j+1:02d}",
                    "announcement_date": datetime.now().strftime("%Y-%m-%d"),
                    "deadline_date": (datetime.now() + timedelta(days=7+i+j)).strftime("%Y-%m-%d"),
                    "estimated_price": f"{(i+j+1)*15000000:,}ì›",
                    "currency": "KRW",
                    "source_url": f"https://test.g2b.go.kr/bid/{i+1}{j+1}",
                    "source_site": "G2B",
                    "country": "KR",
                    "keywords": [keyword],
                    "relevance_score": 8.5 - (i+j)*0.5,
                    "urgency_level": "medium",
                    "status": "active",
                    "extra_data": {
                        "crawled_at": datetime.now().isoformat(),
                        "category": category,
                        "bid_notice_order": f"{j+1}",
                        "api_data": False,
                        "api_service": "BidPublicInfoService",
                        "dummy_data": True,
                        "note": "G2B API í‚¤ ì—†ìŒìœ¼ë¡œ ì¸í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„°"
                    }
                }
                dummy_bids.append(dummy_bid)

        logger.info(f"G2B API ë”ë¯¸ ë°ì´í„° {len(dummy_bids)}ê±´ ìƒì„±")
        return dummy_bids
