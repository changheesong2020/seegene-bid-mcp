"""G2B (ë‚˜ë¼ì¥í„°) API Crawler."""

import asyncio
import aiohttp
import json
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from urllib.parse import quote

from src.crawler.base import BaseCrawler
from src.config import settings
from src.database.connection import DatabaseManager
from src.utils.logger import get_logger

logger = get_logger(__name__)


class G2BCrawler(BaseCrawler):
    """ë‚˜ë¼ì¥í„°(G2B) API í¬ë¡¤ëŸ¬"""

    def __init__(self):
        super().__init__("G2B", "KR")
        self.api_key = settings.G2B_API_KEY
        self.encoded_api_key = self._prepare_service_key(self.api_key)

        # BidPublicInfoService ì„¤ì •
        # ìµœê·¼ data.go.kr API ê²½ë¡œê°€ 02 ë²„ì „ìœ¼ë¡œ ë³€ê²½ë˜ë©´ì„œ ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ì—ì„œ 404ê°€
        # ë°œìƒí•˜ëŠ” ì‚¬ë¡€ê°€ ìˆì–´ ë‹¤ì¤‘ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì¤€ë¹„í•œë‹¤.
        self.api_base_url_candidates: List[str] = [
            "https://apis.data.go.kr/1230000/ad/BidPublicInfoService02",
            "https://apis.data.go.kr/1230000/ad/BidPublicInfoService",
            "https://apis.data.go.kr/1230000/BidPublicInfoService02",
            "https://apis.data.go.kr/1230000/BidPublicInfoService",
        ]
        self.active_api_base_url: Optional[str] = None
        self.operations = {
            "cnstwk": ("getBidPblancListInfoCnstwkPPSSrch", "ê³µì‚¬"),
            "servc": ("getBidPblancListInfoServcPPSSrch", "ìš©ì—­"),
            "thng": ("getBidPblancListInfoThngPPSSrch", "ë¬¼í’ˆ"),
            "frgcpt": ("getBidPblancListInfoFrgcptPPSSrch", "ì™¸ì"),
        }
        self.api_request_timeout = aiohttp.ClientTimeout(total=20)
        self.api_rate_limit_tps = 30
        self.api_rows_per_page = 50  # í˜ì´ì§€ í¬ê¸° ì¤„ì—¬ì„œ API ì œí•œ íšŒí”¼

        # ê³µê³µë°ì´í„°ê°œë°©í‘œì¤€ì„œë¹„ìŠ¤ ì„¤ì • (ë°±ì—…ìš©)
        self.standard_api_base_url = "https://apis.data.go.kr/1230000/ao/PubDataOpnStdService"
        self.standard_operation = "getDataSetOpnStdBidPblancInfo"

    async def login(self) -> bool:
        """API ê¸°ë°˜ì´ë¯€ë¡œ ë¡œê·¸ì¸ ë¶ˆí•„ìš”"""
        if not self.encoded_api_key:
            logger.warning("G2B API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            logger.warning("data.go.krì—ì„œ 'ëˆ„ë¦¬ì¥í„° ë¯¼ê°„ì…ì°°ê³µê³ ì„œë¹„ìŠ¤' API í‚¤ë¥¼ ë°œê¸‰ë°›ì•„ .env íŒŒì¼ì˜ G2B_API_KEYì— ì„¤ì •í•˜ì„¸ìš”.")
            return False

        logger.info("G2B API í‚¤ ì¸ì¦ ì¤€ë¹„ ì™„ë£Œ")
        return True

    def setup_driver(self):
        """API ê¸°ë°˜ì´ë¯€ë¡œ WebDriver ë¶ˆí•„ìš”"""
        logger.info("G2B API í¬ë¡¤ëŸ¬ - WebDriver ì„¤ì • ìŠ¤í‚µ")

    def teardown_driver(self):
        """API ê¸°ë°˜ì´ë¯€ë¡œ ì •ë¦¬ ì‘ì—… ë¶ˆí•„ìš”"""
        logger.info("G2B API í¬ë¡¤ëŸ¬ - WebDriver ì •ë¦¬ ìŠ¤í‚µ")

    async def search_bids(self, keywords: List[str]) -> List[Dict[str, Any]]:
        """ì…ì°° ì •ë³´ ê²€ìƒ‰ - í‚¤ì›Œë“œë³„ ê°œë³„ ê²€ìƒ‰"""
        if not self.encoded_api_key:
            logger.warning("G2B API í‚¤ê°€ ì—†ì–´ ê²€ìƒ‰ ë¶ˆê°€")
            return []

        all_results: List[Dict[str, Any]] = []

        try:
            # í‚¤ì›Œë“œê°€ ì œê³µë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ í‚¤ì›Œë“œ ì‚¬ìš©
            if not keywords:
                keywords = ["PCR", "ì§„ë‹¨í‚¤íŠ¸", "ë¶„ìì§„ë‹¨", "ì²´ì™¸ì§„ë‹¨", "ì˜ë£Œê¸°ê¸°"]

            logger.info(f"ğŸ‡°ğŸ‡· G2B API í‚¤ì›Œë“œë³„ ê°œë³„ ê²€ìƒ‰ ì‹œì‘")
            logger.info(f"ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ: {keywords}")

            # API ì„œë¹„ìŠ¤ ê°€ìš©ì„± ì‚¬ì „ ì²´í¬
            service_available = await self._check_api_service_availability()
            if not service_available:
                logger.error("ğŸš« G2B API ì„œë¹„ìŠ¤ê°€ í˜„ì¬ ì´ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤")
                logger.error("ğŸ’¡ í•´ê²° ë°©ë²•:")
                logger.error("   1. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”")
                logger.error("   2. data.go.kr ì„œë¹„ìŠ¤ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”")
                logger.error("   3. ëŒ€ì•ˆ: ë‚˜ë¼ì¥í„° ì›¹ì‚¬ì´íŠ¸ ì§ì ‘ í¬ë¡¤ë§ ê³ ë ¤")
                return []

            # ê° í‚¤ì›Œë“œë³„ë¡œ ê°œë³„ ê²€ìƒ‰
            successful_searches = 0
            for i, keyword in enumerate(keywords, 1):
                try:
                    logger.info(f"[{i}/{len(keywords)}] í‚¤ì›Œë“œ '{keyword}' ê²€ìƒ‰ ì¤‘...")
                    keyword_results = []

                    # BidPublicInfoService API ê²€ìƒ‰ (ì¹´í…Œê³ ë¦¬ë³„)
                    for category, (operation, label) in self.operations.items():
                        log_label = label if label == category else f"{label}({category})"
                        logger.info(f"  ğŸ“¡ [{keyword}] {log_label} ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰")

                        results = await self._search_bid_public_info(
                            operation, category, [keyword], display_name=label
                        )

                        if results:
                            keyword_results.extend(results)
                            logger.info(f"  âœ… [{keyword}] {log_label}ì—ì„œ {len(results)}ê±´ ìˆ˜ì§‘")
                            successful_searches += 1
                        else:
                            logger.info(f"  âšª [{keyword}] {log_label} ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")

                        await asyncio.sleep(0.5)  # ì¹´í…Œê³ ë¦¬ ê°„ ì§§ì€ ëŒ€ê¸°

                    # í‘œì¤€ APIë¡œë„ ê²€ìƒ‰ (ì¼ì‹œì ìœ¼ë¡œ ë¹„í™œì„±í™” - ì„±ëŠ¥ ê°œì„ )
                    # try:
                    #     standard_results = await self._search_standard_api([keyword])
                    #     if standard_results:
                    #         keyword_results.extend(standard_results)
                    #         logger.info(f"  ğŸ“¦ [{keyword}] í‘œì¤€ APIì—ì„œ {len(standard_results)}ê±´ ì¶”ê°€")
                    # except Exception as e:
                    #     logger.warning(f"  âš ï¸ [{keyword}] í‘œì¤€ API ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    logger.info(f"  â­ï¸ [{keyword}] í‘œì¤€ API ê²€ìƒ‰ ìŠ¤í‚µ (ì„±ëŠ¥ ìµœì í™”)")

                    all_results.extend(keyword_results)
                    logger.info(f"âœ… í‚¤ì›Œë“œ '{keyword}' ì´ {len(keyword_results)}ê±´ ìˆ˜ì§‘")

                    # í‚¤ì›Œë“œ ê°„ ëŒ€ê¸° (API ì œí•œ ì¤€ìˆ˜)
                    if i < len(keywords):
                        await asyncio.sleep(1)

                except Exception as e:
                    logger.warning(f"âš ï¸ í‚¤ì›Œë“œ '{keyword}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    continue

            # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
            if successful_searches == 0:
                logger.warning("ğŸš¨ ëª¨ë“  G2B API ê²€ìƒ‰ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
                logger.warning("ğŸ“‹ ê°€ëŠ¥í•œ ì›ì¸:")
                logger.warning("   - API ì„œë¹„ìŠ¤ ì¼ì‹œì  ì¤‘ë‹¨")
                logger.warning("   - API í‚¤ ê¶Œí•œ ë¬¸ì œ")
                logger.warning("   - ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ")
                return []

            # ì¤‘ë³µ ì œê±°
            unique_results = self._remove_duplicates(all_results)

            logger.info(f"âœ… G2B í‚¤ì›Œë“œë³„ ê²€ìƒ‰ ì™„ë£Œ: ì „ì²´ {len(all_results)}ê±´ ìˆ˜ì§‘ â†’ ì¤‘ë³µ ì œê±° í›„ {len(unique_results)}ê±´")

            # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            if unique_results:
                try:
                    await DatabaseManager.save_bid_info(unique_results)
                    logger.info(f"ğŸ’¾ G2B ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ: {len(unique_results)}ê±´")
                except Exception as e:
                    logger.error(f"âŒ G2B ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
            else:
                logger.info("ğŸ“ G2B ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")

            return unique_results

        except Exception as e:
            logger.error(f"âŒ G2B API ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return all_results

    def _get_prioritized_api_base_urls(self) -> List[str]:
        """ìµœê·¼ ì„±ê³µí•œ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‹œë„"""
        if self.active_api_base_url and self.active_api_base_url in self.api_base_url_candidates:
            prioritized = [self.active_api_base_url]
            prioritized.extend(
                [url for url in self.api_base_url_candidates if url != self.active_api_base_url]
            )
            return prioritized
        return self.api_base_url_candidates

    async def _request_bid_public_info(
        self,
        session: aiohttp.ClientSession,
        operation: str,
        params: Dict[str, Any],
        category_label: str,
    ) -> Optional[str]:
        """ì—”ë“œí¬ì¸íŠ¸ í›„ë³´ë¥¼ ìˆœíšŒí•˜ë©° BidPublicInfoService ì‘ë‹µì„ ê°€ì ¸ì˜¨ë‹¤."""

        last_status: Optional[int] = None
        service_unavailable_count = 0

        for base_url in self._get_prioritized_api_base_urls():
            url = f"{base_url}/{operation}"
            try:
                async with session.get(url, params=params) as response:
                    last_status = response.status

                    if response.status == 200:
                        if base_url != self.active_api_base_url:
                            logger.info(f"[{category_label}] G2B API ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©: {base_url}")
                        self.active_api_base_url = base_url
                        return await response.text()

                    if response.status == 404:
                        logger.warning(
                            f"[{category_label}] ì—”ë“œí¬ì¸íŠ¸ {url} ì—ì„œ 404 ì‘ë‹µ - ë‹¤ë¥¸ ê²½ë¡œ ì‹œë„"
                        )
                        if self.active_api_base_url == base_url:
                            self.active_api_base_url = None
                        continue

                    if response.status == 503:
                        service_unavailable_count += 1
                        logger.warning(
                            f"[{category_label}] ì—”ë“œí¬ì¸íŠ¸ {url} ì—ì„œ 503 ì„œë¹„ìŠ¤ ë¶ˆê°€ ì‘ë‹µ - ë‹¤ë¥¸ ê²½ë¡œ ì‹œë„"
                        )
                        if self.active_api_base_url == base_url:
                            self.active_api_base_url = None
                        continue

                    error_text = await response.text()
                    logger.error(
                        f"[{category_label}] API í˜¸ì¶œ ì‹¤íŒ¨: {response.status}"
                    )
                    if error_text:
                        logger.debug(f"[{category_label}] API ì‹¤íŒ¨ ì‘ë‹µ: {error_text[:200]}")
                    return None

            except Exception as e:
                logger.error(f"[{category_label}] API í˜¸ì¶œ ì¤‘ ì˜ˆì™¸ ë°œìƒ ({url}): {e}")
                if self.active_api_base_url == base_url:
                    self.active_api_base_url = None
                continue

        # ì„œë¹„ìŠ¤ ìƒíƒœì— ë”°ë¥¸ ì ì ˆí•œ ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥
        if service_unavailable_count == len(self.api_base_url_candidates):
            logger.error(f"[{category_label}] G2B API ì„œë¹„ìŠ¤ê°€ í˜„ì¬ ì´ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤ (503 Service Unavailable)")
            logger.error(f"[{category_label}] í•´ê²° ë°©ë²•: 1) ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„, 2) data.go.kr ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸, 3) API í‚¤ ìœ íš¨ì„± ê²€ì¦")
        elif last_status == 404:
            logger.error(f"[{category_label}] ëª¨ë“  G2B ì—”ë“œí¬ì¸íŠ¸ì—ì„œ 404 ì‘ë‹µ")
            logger.error(f"[{category_label}] G2B API êµ¬ì¡°ê°€ ë³€ê²½ë˜ì—ˆì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤. ìµœì‹  API ë¬¸ì„œë¥¼ í™•ì¸í•˜ì„¸ìš”.")

        return None

    async def _search_bid_public_info(
        self,
        operation: str,
        category: str,
        keywords: List[str],
        display_name: Optional[str] = None,
    ) -> List[Dict[str, Any]]:
        """BidPublicInfoService API ê²€ìƒ‰"""
        results: List[Dict[str, Any]] = []

        try:
            category_label = display_name or category
            if not self.encoded_api_key:
                logger.warning("ìœ íš¨í•œ G2B API í‚¤ê°€ ì—†ì–´ BidPublicInfoService í˜¸ì¶œì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                return results

            end_date = datetime.now()
            start_date = end_date - timedelta(days=30)  # 30ì¼ë¡œ ë‹¨ì¶•í•˜ì—¬ API ì œí•œ íšŒí”¼

            base_params = {
                "ServiceKey": self.encoded_api_key,
                "type": "json",
                "numOfRows": self.api_rows_per_page,
                "inqryDiv": "1",  # ë“±ë¡ì¼ì‹œ ê¸°ì¤€
                "inqryBgnDt": start_date.strftime("%Y%m%d0000"),  # ì‹œê°„ì„ 0000ìœ¼ë¡œ ê³ ì •
                "inqryEndDt": end_date.strftime("%Y%m%d2359"),    # ì‹œê°„ì„ 2359ë¡œ ê³ ì •
            }
            search_params = self._build_search_query_params(category, keywords, start_date, end_date)

            timeout = self.api_request_timeout

            async with aiohttp.ClientSession(timeout=timeout) as session:
                page_no = 1
                total_count: Optional[int] = None

                while True:
                    request_params = {**base_params, **search_params, "pageNo": page_no}
                    json_data: Optional[Dict[str, Any]] = None
                    should_break = False

                    data = await self._request_bid_public_info(
                        session, operation, request_params, category_label
                    )

                    if data is None:
                        should_break = True
                    else:
                        if not data.strip():
                            logger.warning(
                                f"[{category_label}] APIì—ì„œ ë¹ˆ ì‘ë‹µ ìˆ˜ì‹  (page {page_no})"
                            )
                            should_break = True
                        else:
                            try:
                                json_data = json.loads(data)
                            except json.JSONDecodeError:
                                logger.error(
                                    f"[{category_label}] API ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‘ë‹µ ë‚´ìš©: {data[:200]}"
                                )
                                should_break = True

                    if should_break:
                        break

                    if json_data is None:
                        break

                    page_results = await self._parse_api_response(
                        json_data, category, keywords, display_name=display_name
                    )
                    if page_results:
                        results.extend(page_results)

                    if total_count is None:
                        total_count = self._extract_total_count(json_data)

                    if not page_results:
                        logger.info(f"[{category_label}] ë” ì´ìƒ ê²°ê³¼ê°€ ì—†ì–´ í˜ì´ì§€ ìˆœíšŒë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                        break

                    if total_count is not None and page_no * self.api_rows_per_page >= total_count:
                        break

                    page_no += 1
                    await asyncio.sleep(1 / self.api_rate_limit_tps)

        except Exception as e:
            logger.error(f"ì¹´í…Œê³ ë¦¬ '{category}' API ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")

        return results

    def _build_search_query_params(
        self,
        category: str,
        keywords: List[str],
        start_date: datetime,
        end_date: datetime,
    ) -> Dict[str, Any]:
        """ë‚˜ë¼ì¥í„° ê²€ìƒ‰ì¡°ê±´ì„ PPS ì „ìš© ê²€ìƒ‰ íŒŒë¼ë¯¸í„°ë¡œ ë§¤í•‘ (í‚¤ì›Œë“œ ê²€ìƒ‰ ê°•í™”)"""

        params: Dict[str, Any] = {
            "searchDtType": "1",  # 1: ë“±ë¡ì¼ì‹œ ê¸°ì¤€ ê²€ìƒ‰
            "searchBgnDt": start_date.strftime("%Y%m%d"),
            "searchEndDt": end_date.strftime("%Y%m%d"),
        }

        # í‚¤ì›Œë“œ ì •ë¦¬ ë° ê²€ì¦
        sanitized_keywords: List[str] = []
        seen = set()
        for keyword in keywords:
            if not keyword:
                continue
            cleaned = keyword.strip()
            if not cleaned or cleaned in seen:
                continue
            sanitized_keywords.append(cleaned)
            seen.add(cleaned)

        if sanitized_keywords:
            # G2B APIëŠ” OR ë¬¸ë²•ì„ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì²« ë²ˆì§¸ í‚¤ì›Œë“œë§Œ ëŒ€í‘œ ê²€ìƒ‰ì–´ë¡œ ì‚¬ìš©
            main_keyword = sanitized_keywords[0]

            params.update({
                "searchType": "1",  # 1: ê³µê³ ëª… ê²€ìƒ‰
                "searchWrd": main_keyword,
                "bidNtceNm": main_keyword,
                # ì¶”ê°€ ê²€ìƒ‰ ì˜µì…˜
                "searchCndtnType": "1",  # ê²€ìƒ‰ ì¡°ê±´ íƒ€ì…
                "kwdSearch": "Y",  # í‚¤ì›Œë“œ ê²€ìƒ‰ í™œì„±í™”
            })

            # ê°œë³„ í‚¤ì›Œë“œë¡œë„ ê²€ìƒ‰ (ë” ë„“ì€ ë²”ìœ„)
            for i, keyword in enumerate(sanitized_keywords[:3]):  # ìµœëŒ€ 3ê°œ í‚¤ì›Œë“œ
                if i == 0:
                    params[f"bidNtceNm01"] = keyword
                elif i == 1:
                    params[f"bidNtceNm02"] = keyword
                elif i == 2:
                    params[f"bidNtceNm03"] = keyword

            logger.info(f"ğŸ” G2B ëŒ€í‘œ ê²€ìƒ‰ì–´: {main_keyword}")
            if len(sanitized_keywords) > 1:
                logger.info(f"ğŸ“‹ ì¶”ê°€ í‚¤ì›Œë“œëŠ” ê°œë³„ íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬: {sanitized_keywords[1:]}")
            logger.info(f"ğŸ“‹ ì „ì²´ ê²€ìƒ‰ í‚¤ì›Œë“œ: {sanitized_keywords}")
        else:
            # í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì „ì²´ ê²€ìƒ‰
            params.update({
                "searchType": "0",  # 0: ì „ì²´ ê²€ìƒ‰
                "kwdSearch": "N"
            })
            logger.info("ğŸ“¥ G2B ì „ì²´ ê²€ìƒ‰ (í‚¤ì›Œë“œ ë¯¸ì§€ì •)")

        return params

    async def _search_standard_api(self, keywords: List[str]) -> List[Dict[str, Any]]:
        """ê³µê³µë°ì´í„°ê°œë°©í‘œì¤€ì„œë¹„ìŠ¤ API ê²€ìƒ‰ (í‚¤ì›Œë“œ ê¸°ë°˜)"""
        results: List[Dict[str, Any]] = []

        try:
            if not self.encoded_api_key:
                logger.warning("ìœ íš¨í•œ G2B API í‚¤ê°€ ì—†ì–´ í‘œì¤€ API í˜¸ì¶œì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                return results

            end_date = datetime.now()
            start_date = end_date - timedelta(days=30)  # 30ì¼ë¡œ ë‹¨ì¶•í•˜ì—¬ API ì œí•œ íšŒí”¼

            # ê¸°ë³¸ ë§¤ê°œë³€ìˆ˜
            base_params = {
                "ServiceKey": self.encoded_api_key,
                "type": "json",
                "numOfRows": self.api_rows_per_page,
                "pageNo": 1,
                "bidNtceBgnDt": start_date.strftime("%Y%m%d0000"),
                "bidNtceEndDt": end_date.strftime("%Y%m%d2359"),
            }

            # í‚¤ì›Œë“œ ê²€ìƒ‰ ë§¤ê°œë³€ìˆ˜ ì¶”ê°€
            if keywords:
                # í‚¤ì›Œë“œ ì •ë¦¬
                sanitized_keywords = [kw.strip() for kw in keywords if kw.strip()]

                if sanitized_keywords:
                    # ì²« ë²ˆì§¸ í‚¤ì›Œë“œë¥¼ ë©”ì¸ ê²€ìƒ‰ì–´ë¡œ ì‚¬ìš©
                    main_keyword = sanitized_keywords[0]
                    base_params.update({
                        "bidNtceNm": main_keyword,  # ê³µê³ ëª… ê²€ìƒ‰
                        "searchWrd": main_keyword,   # ê²€ìƒ‰ì–´
                    })
                    logger.info(f"ğŸ” í‘œì¤€ API í‚¤ì›Œë“œ ê²€ìƒ‰: {main_keyword}")
                else:
                    logger.info("ğŸ“‹ í‘œì¤€ API ì „ì²´ ê²€ìƒ‰ (ìœ íš¨í•œ í‚¤ì›Œë“œ ì—†ìŒ)")
            else:
                logger.info("ğŸ“‹ í‘œì¤€ API ì „ì²´ ê²€ìƒ‰ (í‚¤ì›Œë“œ ë¯¸ì œê³µ)")

            params = base_params

            logger.info(f"ğŸ” í‘œì¤€ API ê²€ìƒ‰ - ê¸°ê°„: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}")

            async with aiohttp.ClientSession(timeout=self.api_request_timeout) as session:
                url = f"{self.standard_api_base_url}/{self.standard_operation}"

                async with session.get(url, params=params) as response:
                    if response.status != 200:
                        logger.error(f"í‘œì¤€ API í˜¸ì¶œ ì‹¤íŒ¨: {response.status}")
                        return results

                    data = await response.text()
                    logger.info(f"í‘œì¤€ API ì‘ë‹µ ë‚´ìš© (ì²˜ìŒ 300ì): {data[:300]}")

                    if not data.strip():
                        logger.warning("í‘œì¤€ APIì—ì„œ ë¹ˆ ì‘ë‹µ ìˆ˜ì‹ ")
                        return results

                    if data.strip().startswith('<OpenAPI_ServiceResponse>'):
                        logger.error("G2B í‘œì¤€ API ì¸ì¦ ì˜¤ë¥˜ - XML ì˜¤ë¥˜ ì‘ë‹µ ìˆ˜ì‹ ")
                        if 'SERVICE_ACCESS_DENIED_ERROR' in data and self.api_key:
                            masked_key = self._mask_api_key(self.api_key)
                            logger.error("ğŸš« G2B API í‚¤ ì¸ì¦ ì‹¤íŒ¨ (ì˜¤ë¥˜ì½”ë“œ: 20)")
                            logger.error("ğŸ“‹ í•´ê²° ë°©ë²•:")
                            logger.error("   1. data.go.kr ê³µê³µë°ì´í„°í¬í„¸ ì ‘ì†")
                            logger.error("   2. 'ë‚˜ë¼ì¥í„° ê³µê³µë°ì´í„°ê°œë°©í‘œì¤€ì„œë¹„ìŠ¤' ê²€ìƒ‰ ë° í™œìš©ì‹ ì²­")
                            logger.error("   3. ìŠ¹ì¸ëœ API í‚¤ë¥¼ .env íŒŒì¼ì˜ G2B_API_KEYì— ì„¤ì •")
                            logger.error(f"   4. í˜„ì¬ ì„¤ì •ëœ í‚¤: {masked_key}")
                        logger.error(f"ğŸ“„ ì „ì²´ ì˜¤ë¥˜ ì‘ë‹µ: {data}")
                        return results

                    try:
                        json_data = json.loads(data)
                        logger.info(
                            "í‘œì¤€ API JSON íŒŒì‹± ì„±ê³µ. ì‘ë‹µ êµ¬ì¡°: "
                            f"{list(json_data.keys()) if isinstance(json_data, dict) else type(json_data)}"
                        )
                    except json.JSONDecodeError as e:
                        logger.error(f"í‘œì¤€ API JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        logger.error(f"ì‘ë‹µ ë‚´ìš©: {data}")
                        return results

                    results = await self._parse_standard_api_response(json_data, keywords)

        except Exception as e:
            logger.error(f"í‘œì¤€ API ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")

        return results

    async def _parse_api_response(
        self,
        json_data: Dict[str, Any],
        category: str,
        keywords: List[str],
        display_name: Optional[str] = None,
    ) -> List[Dict[str, Any]]:
        """BidPublicInfoService API ì‘ë‹µ ë°ì´í„° íŒŒì‹±"""
        results: List[Dict[str, Any]] = []
        category_label = display_name or category

        try:
            if 'response' not in json_data:
                logger.warning("API ì‘ë‹µì— 'response' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
                # ResponseError í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸
                if 'nkoneps.com.response.ResponseError' in json_data:
                    error_info = json_data['nkoneps.com.response.ResponseError']
                    error_header = error_info.get('header', {})
                    error_code = error_header.get('resultCode', '')
                    error_msg = error_header.get('resultMsg', '')
                    logger.error(f"G2B API ì˜¤ë¥˜ ë°œìƒ - ì½”ë“œ: {error_code}, ë©”ì‹œì§€: {error_msg}")

                    if error_code == '07':
                        logger.error("ì…ë ¥ë²”ìœ„ê°’ ì´ˆê³¼ ì—ëŸ¬ - API ìš”ì²­ íŒŒë¼ë¯¸í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”")
                        logger.error("í•´ê²° ë°©ë²•: 1) ê²€ìƒ‰ ê¸°ê°„ ë‹¨ì¶•, 2) í˜ì´ì§€ í¬ê¸° ê°ì†Œ, 3) íŒŒë¼ë¯¸í„° ê°’ ê²€ì¦")
                return results

            response = json_data['response']
            header = response.get('header', {})
            result_code = header.get('resultCode') or header.get('resultcode')
            if result_code != '00':
                logger.warning(f"API ì˜¤ë¥˜: {header.get('resultMsg', 'Unknown error')} (ì½”ë“œ: {result_code})")
                return results

            body = response.get('body', {})
            items = body.get('items', [])

            if not items:
                logger.info(f"ì¹´í…Œê³ ë¦¬ '{category_label}'ì—ì„œ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                return results

            # ì‹¤ì œ ë°˜í™˜ëœ ë°ì´í„° í™•ì¸ì„ ìœ„í•œ ë¡œê·¸
            logger.info(f"ğŸ“‹ {category_label} - APIì—ì„œ {len(items)}ê±´ì˜ ì…ì°° ë°ì´í„° ë°˜í™˜")
            if len(items) > 0:
                first_item = items[0]
                logger.info(f"ğŸ“„ ì²« ë²ˆì§¸ ì•„ì´í…œ ìƒ˜í”Œ: {first_item.get('bidNtceNm', first_item.get('ntceNm', 'ì œëª©ì—†ìŒ'))}")

            items = self._normalize_items(items)

            for item in items:
                try:
                    title = self._get_first_non_empty(item, ['bidNtceNm', 'ntceNm', 'bidNm'])
                    organization = self._get_first_non_empty(item, ['ntceInsttNm', 'dminsttNm', 'insttNm'])

                    # í‚¤ì›Œë“œ ê´€ë ¨ì„± í™•ì¸
                    if not self._is_keyword_relevant(title, organization, keywords):
                        continue

                    deadline_date = self._get_first_non_empty(item, ['bidClseDt', 'bidClseDt1', 'bidClseDt2'])
                    estimated_price_raw = self._get_first_non_empty(
                        item, ['presmptPrce', 'asignBdgtAmt', 'bdgtAmt', 'refAmt']
                    )

                    logger.info(f"ğŸ“ [{category_label}] {title[:80]}")
                    logger.info(f"    ğŸ¢ ë°œì£¼ê¸°ê´€: {organization}")
                    logger.info(f"    ğŸ’° ì¶”ì •ê°€ê²©: {self._format_price(estimated_price_raw)}")
                    logger.info(f"    ğŸ“… ë§ˆê°ì¼: {deadline_date}")

                    relevance_score = self.calculate_relevance_score(title, organization)
                    urgency_level = self.determine_urgency_level(deadline_date)

                    bid_number = item.get('bidNtceNo', '')
                    bid_notice_order = item.get('bidNtceOrd', '')
                    announcement_date_raw = self._get_first_non_empty(
                        item, ['bidNtceDt', 'rgstDt', 'ntceDt']
                    )
                    estimated_price_raw = self._get_first_non_empty(
                        item, ['presmptPrce', 'asignBdgtAmt', 'bdgtAmt', 'refAmt']
                    )
                    budget_amount_raw = self._get_first_non_empty(
                        item, ['asignBdgtAmt', 'bdgtAmt', 'presmptPrce']
                    )

                    detail_url = self._get_first_non_empty(item, ['bidNtceDtlUrl', 'bidNtceUrl']) or self._generate_detail_url(
                        bid_number,
                        bid_notice_order
                    )

                    bid_info = {
                        "title": title,
                        "organization": organization,
                        "bid_number": bid_number,
                        "announcement_date": self._format_date(announcement_date_raw),
                        "deadline_date": self._format_date(deadline_date),
                        "estimated_price": self._format_price(estimated_price_raw),
                        "currency": "KRW",
                        "source_url": detail_url,
                        "source_site": "G2B",
                        "country": "KR",
                        "keywords": self._extract_keywords(title, organization),
                        "relevance_score": relevance_score,
                        "urgency_level": urgency_level,
                        "status": "active",
                        "extra_data": {
                            "crawled_at": datetime.now().isoformat(),
                            "category": category,
                            "category_label": category_label,
                            "bid_method": item.get('bidMethdNm', ''),
                            "contract_method": self._get_first_non_empty(
                                item, ['cntrctCnclsMthdNm', 'cntrctMthdNm']
                            ),
                            "bid_qualification": self._get_first_non_empty(item, ['bidQlfctNm', 'bidPrtcptQlfctNm']),
                            "opening_date": self._format_date(self._get_first_non_empty(item, ['opengDt', 'bidOpenDt'])),
                            "opening_place": self._get_first_non_empty(item, ['opengPlce', 'bidOpenPlce']),
                            "contact_name": self._get_first_non_empty(item, ['ofclNm', 'chrgePerNm']),
                            "contact_phone": self._get_first_non_empty(item, ['ofclTelNo', 'chrgePerTel']),
                            "contact_email": self._get_first_non_empty(item, ['ofclEmail', 'chrgePerEmail']),
                            "reference_number": self._get_first_non_empty(item, ['refNo', 'bidNtceRefNo']),
                            "notice_division": self._get_first_non_empty(item, ['ntceDivNm', 'ntceKindNm']),
                            "vat_included": self._get_first_non_empty(item, ['vatInclsnYnNm', 'vatYnNm']),
                            "budget_amount": self._format_price(budget_amount_raw),
                            "region_limit": self._get_first_non_empty(item, ['rgnLmtDivNm', 'bidAreaLmtYnNm']),
                            "bid_notice_order": bid_notice_order,
                            "api_data": True,
                            "api_service": "BidPublicInfoService"
                        }
                    }

                    results.append(bid_info)

                except Exception as e:
                    logger.warning(f"[{category_label}] ê°œë³„ ì•„ì´í…œ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
                    continue

        except Exception as e:
            logger.error(f"[{category_label}] API ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")

        if results:
            logger.info(f"âœ… [{category_label}] ìˆ˜ì§‘ ì™„ë£Œ: {len(results)}ê±´")
        else:
            logger.info(f"âŒ [{category_label}] ìˆ˜ì§‘ ê²°ê³¼ ì—†ìŒ")

        return results

    async def _parse_standard_api_response(self, json_data: Dict[str, Any], keywords: List[str]) -> List[Dict[str, Any]]:
        """ê³µê³µë°ì´í„°ê°œë°©í‘œì¤€ì„œë¹„ìŠ¤ API ì‘ë‹µ ë°ì´í„° íŒŒì‹±"""
        results: List[Dict[str, Any]] = []

        try:
            if 'response' not in json_data:
                logger.warning("í‘œì¤€ API ì‘ë‹µì— 'response' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
                # ResponseError í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸
                if 'nkoneps.com.response.ResponseError' in json_data:
                    error_info = json_data['nkoneps.com.response.ResponseError']
                    error_header = error_info.get('header', {})
                    error_code = error_header.get('resultCode', '')
                    error_msg = error_header.get('resultMsg', '')
                    logger.error(f"í‘œì¤€ API ì˜¤ë¥˜ ë°œìƒ - ì½”ë“œ: {error_code}, ë©”ì‹œì§€: {error_msg}")

                    if error_code == '07':
                        logger.error("ì…ë ¥ë²”ìœ„ê°’ ì´ˆê³¼ ì—ëŸ¬ - API ìš”ì²­ íŒŒë¼ë¯¸í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”")
                        logger.error("í•´ê²° ë°©ë²•: 1) ê²€ìƒ‰ ê¸°ê°„ ë‹¨ì¶•, 2) í˜ì´ì§€ í¬ê¸° ê°ì†Œ, 3) íŒŒë¼ë¯¸í„° ê°’ ê²€ì¦")
                return results

            response = json_data['response']
            header = response.get('header', {})
            result_code = header.get('resultCode') or header.get('resultcode')
            if result_code != '00':
                logger.warning(f"í‘œì¤€ API ì˜¤ë¥˜: {header.get('resultMsg', 'Unknown error')} (ì½”ë“œ: {result_code})")
                return results

            body = response.get('body', {})
            items = body.get('items', [])
            total_count = body.get('totalCount', 0)

            logger.info(f"ğŸ“Š í‘œì¤€ API ì „ì²´ ê²°ê³¼ ìˆ˜: {total_count}ê±´")
            logger.info(f"ğŸ” items íƒ€ì…: {type(items)}, ê¸¸ì´: {len(items) if isinstance(items, list) else 'N/A'}")

            # ì‘ë‹µ êµ¬ì¡° ë””ë²„ê¹…
            if items and isinstance(items, list) and len(items) > 0:
                logger.info(f"ğŸ“„ ì²« ë²ˆì§¸ ì•„ì´í…œ ìƒ˜í”Œ í‚¤ë“¤: {list(items[0].keys())}")
                logger.info(f"ğŸ“„ ì²« ë²ˆì§¸ ì•„ì´í…œ ì „ì²´: {items[0]}")

            if not items:
                logger.info("í‘œì¤€ API ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                return results

            items = self._normalize_items(items)

            for idx, item in enumerate(items):
                try:
                    title = item.get('ntceNm', '')
                    organization = item.get('ntceInsttNm', '')

                    # logger.info(f"ğŸ“‹ í‘œì¤€ API ì…ì°°ì œëª©: {title}")  # ì¤‘ë³µ ë¡œê·¸ ì œê±°

                    # í‚¤ì›Œë“œ ê´€ë ¨ì„± í™•ì¸
                    if not self._is_keyword_relevant(title, organization, keywords):
                        continue

                    deadline_date = item.get('bidClseDate', '')
                    estimated_price = item.get('presmptPrce', '')

                    logger.info(f"ğŸ“ [{idx+1}] {title[:80]}")
                    logger.info(f"    ğŸ¢ ë°œì£¼ê¸°ê´€: {organization}")
                    logger.info(f"    ğŸ’° ì¶”ì •ê°€ê²©: {self._format_price(estimated_price)}")
                    logger.info(f"    ğŸ“… ë§ˆê°ì¼: {deadline_date}")

                    relevance_score = self.calculate_relevance_score(title, organization)
                    urgency_level = self.determine_urgency_level(deadline_date)

                    bid_number = item.get('bidNtceNo', '')
                    bid_notice_order = item.get('bidNtceOrd', '')

                    bid_info = {
                        "title": title,
                        "organization": organization,
                        "bid_number": bid_number,
                        "announcement_date": self._format_date(item.get('nticeDt', '')),
                        "deadline_date": self._format_date(deadline_date),
                        "estimated_price": self._format_price(item.get('presmptPrce', '')),
                        "currency": "KRW",
                        "source_url": item.get('bidNtceUrl', ''),
                        "source_site": "G2B",
                        "country": "KR",
                        "keywords": self._extract_keywords(title, organization),
                        "relevance_score": relevance_score,
                        "urgency_level": urgency_level,
                        "status": "active",
                        "extra_data": {
                            "crawled_at": datetime.now().isoformat(),
                            "bid_notice_order": bid_notice_order,
                            "business_division": item.get('bsnsDivNm', ''),
                            "contract_method": item.get('cntrctCnclsMthdNm', ''),
                            "contract_type": item.get('cntrctCnclsSttusNm', ''),
                            "decision_method": item.get('bidwinrDcsnMthdNm', ''),
                            "opening_date": self._format_date(item.get('opengDate', '')),
                            "opening_time": item.get('opengTm', ''),
                            "opening_place": item.get('opengPlce', ''),
                            "budget_amount": self._format_price(item.get('asignBdgtAmt', '')),
                            "international_bid": item.get('intrntnlBidYn', ''),
                            "electronic_bid": item.get('elctrnBidYn', ''),
                            "demand_institution": item.get('dmndInsttNm', ''),
                            "notice_status": item.get('bidNtceSttusNm', ''),
                            "region_limit": item.get('rgnLmtYn', ''),
                            "industry_limit": item.get('indstrytyLmtYn', ''),
                            "api_data": True,
                            "api_service": "OpenDataStandard"
                        }
                    }

                    results.append(bid_info)

                except Exception as e:
                    logger.warning(f"í‘œì¤€ API ê°œë³„ ì•„ì´í…œ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
                    continue

        except Exception as e:
            logger.error(f"í‘œì¤€ API ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")

        if results:
            logger.info(f"âœ… [í‘œì¤€ API] ìˆ˜ì§‘ ì™„ë£Œ: {len(results)}ê±´")
        else:
            logger.info(f"âŒ [í‘œì¤€ API] ìˆ˜ì§‘ ê²°ê³¼ ì—†ìŒ")

        return results

    def _extract_total_count(self, json_data: Dict[str, Any]) -> Optional[int]:
        """ì‘ë‹µì—ì„œ totalCount ê°’ì„ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ"""
        try:
            body = json_data.get("response", {}).get("body", {})
            total = body.get("totalCount")
            if total is None or total == "":
                return None
            return int(total)
        except (ValueError, TypeError, AttributeError):
            return None

    def _matches_keywords(self, title: str, organization: str, keywords: List[str]) -> bool:
        """í‚¤ì›Œë“œ ë§¤ì¹­ í™•ì¸"""
        from src.config import crawler_config

        text = f"{title} {organization}".lower()

        all_keywords: List[str] = []
        all_keywords.extend(crawler_config.SEEGENE_KEYWORDS['korean'])
        all_keywords.extend(crawler_config.SEEGENE_KEYWORDS['english'])

        for keyword in all_keywords:
            if keyword.lower() in text:
                return True

        for keyword in keywords:
            if keyword.lower() in text:
                return True

        return False

    async def _check_api_service_availability(self) -> bool:
        """G2B API ì„œë¹„ìŠ¤ ê°€ìš©ì„± ì²´í¬"""
        try:
            import aiohttp

            # ê¸°ë³¸ API ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=10)) as session:
                for base_url in self.api_base_url_candidates[:2]:  # ì²˜ìŒ 2ê°œë§Œ ì²´í¬
                    try:
                        # ê°„ë‹¨í•œ í—¬ìŠ¤ì²´í¬ë¥¼ ìœ„í•´ ê¸°ë³¸ URLë§Œ ìš”ì²­
                        async with session.get(base_url) as response:
                            if response.status in [200, 404]:  # 404ë„ ì„œë¹„ìŠ¤ê°€ ì‚´ì•„ìˆë‹¤ëŠ” ì˜ë¯¸
                                logger.info(f"G2B API ì„œë¹„ìŠ¤ ê°€ìš©ì„± í™•ì¸: {base_url} (ìƒíƒœ: {response.status})")
                                return True
                            elif response.status == 503:
                                logger.warning(f"G2B API ì„œë¹„ìŠ¤ ë¶ˆê°€: {base_url} (503 Service Unavailable)")
                                continue
                    except Exception as e:
                        logger.debug(f"G2B API ê°€ìš©ì„± ì²´í¬ ì‹¤íŒ¨: {base_url} - {e}")
                        continue

            logger.warning("ëª¨ë“  G2B API ì—”ë“œí¬ì¸íŠ¸ê°€ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            return False

        except Exception as e:
            logger.error(f"G2B API ì„œë¹„ìŠ¤ ê°€ìš©ì„± ì²´í¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def _extract_keywords(self, title: str, organization: str = "") -> List[str]:
        """ì œëª©ê³¼ ê¸°ê´€ëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords: List[str] = []
        text_lower = f"{title} {organization}".lower()

        from src.config import crawler_config
        for keyword in crawler_config.SEEGENE_KEYWORDS['korean']:
            if keyword.lower() in text_lower:
                keywords.append(keyword)
        for keyword in crawler_config.SEEGENE_KEYWORDS['english']:
            if keyword.lower() in text_lower:
                keywords.append(keyword)

        return list(set(keywords))

    def _normalize_items(self, items: Any) -> List[Dict[str, Any]]:
        """API ì‘ë‹µ items êµ¬ì¡°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ê·œí™”"""
        if isinstance(items, list):
            return [item for item in items if isinstance(item, dict)]

        if isinstance(items, dict):
            if 'item' in items:
                nested = items['item']
                if isinstance(nested, list):
                    return [item for item in nested if isinstance(item, dict)]
                if isinstance(nested, dict):
                    return [nested]
            return [items]

        return []

    def _get_first_non_empty(self, item: Dict[str, Any], keys: List[str]) -> str:
        """ì£¼ì–´ì§„ í‚¤ ëª©ë¡ì—ì„œ ê°€ì¥ ë¨¼ì € ë“±ì¥í•˜ëŠ” ìœ íš¨í•œ ê°’ì„ ë°˜í™˜"""
        for key in keys:
            value = item.get(key)
            if value is not None and str(value).strip() != "":
                return value
        return ""

    def _format_date(self, date_str: str) -> str:
        """ë‚ ì§œ í˜•ì‹ ë³€í™˜"""
        if not date_str:
            return ""

        value = str(date_str).strip()
        if not value:
            return ""

        date_formats = [
            "%Y-%m-%d %H:%M:%S",
            "%Y-%m-%d %H:%M",
            "%Y-%m-%d",
            "%Y%m%d%H%M%S",
            "%Y%m%d%H%M",
            "%Y%m%d",
            "%Y/%m/%d",
            "%Y.%m.%d"
        ]

        for fmt in date_formats:
            try:
                parsed_date = datetime.strptime(value, fmt)
                return parsed_date.strftime("%Y-%m-%d")
            except ValueError:
                continue

        if len(value) >= 10:
            return value[:10]
        return value

    def _format_price(self, price_str: str) -> str:
        """ê°€ê²© í˜•ì‹ ë³€í™˜"""
        if price_str is None:
            return ""

        value = str(price_str).strip()
        if not value:
            return ""

        normalized = value.replace(",", "")

        try:
            price_num = float(normalized)
        except ValueError:
            filtered = "".join(ch for ch in normalized if ch.isdigit() or ch == '.')
            if not filtered:
                return value
            try:
                price_num = float(filtered)
            except ValueError:
                return value

        return f"{int(price_num):,}ì›"

    def _generate_detail_url(self, bid_number: str, bid_notice_order: str = "") -> str:
        """ìƒì„¸ í˜ì´ì§€ URL ìƒì„±"""
        if not bid_number:
            return ""
        base_url = "https://www.g2b.go.kr/ep/invitation/publish/bidInfoDtl/bidInfoDtl.do"
        if bid_notice_order:
            return f"{base_url}?bidNo={bid_number}&bidRound={bid_notice_order}"
        return f"{base_url}?bidNo={bid_number}"

    def _remove_duplicates(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì¤‘ë³µ ì œê±°"""
        seen_bid_keys = set()
        unique_results: List[Dict[str, Any]] = []

        for result in results:
            bid_number = result.get('bid_number', '')
            bid_notice_order = ''
            extra_data = result.get('extra_data')
            if isinstance(extra_data, dict):
                bid_notice_order = extra_data.get('bid_notice_order', '')
            bid_key = (bid_number, bid_notice_order)

            if bid_number and bid_key not in seen_bid_keys:
                seen_bid_keys.add(bid_key)
                unique_results.append(result)
            elif not bid_number:
                source_url = result.get('source_url', '')
                if source_url not in [r.get('source_url', '') for r in unique_results]:
                    unique_results.append(result)

        return unique_results

    def parse_deadline(self, deadline_str: str) -> Optional[datetime]:
        """G2B API ë§ˆê°ì¼ íŒŒì‹±"""
        try:
            if not deadline_str or deadline_str.strip() == "":
                return None

            for fmt in ["%Y-%m-%d %H:%M:%S", "%Y-%m-%d", "%Y/%m/%d", "%Y.%m.%d"]:
                try:
                    return datetime.strptime(deadline_str.strip(), fmt)
                except ValueError:
                    continue

            return None

        except Exception:
            return None


    def _prepare_service_key(self, api_key: Optional[str]) -> Optional[str]:
        """ìš”ì²­ì— ì‚¬ìš©í•  ì„œë¹„ìŠ¤ í‚¤ë¥¼ ì „ì²˜ë¦¬"""
        if not api_key:
            return None

        key = api_key.strip()
        if not key:
            return None

        # ì´ë¯¸ ì¸ì½”ë”©ëœ ê²½ìš°(%)ëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
        if "%" in key:
            return key

        try:
            return quote(key, safe="")
        except Exception:
            return key

    def _mask_api_key(self, api_key: str) -> str:
        """API í‚¤ ë§ˆìŠ¤í‚¹"""
        if len(api_key) <= 8:
            return api_key
        return f"{api_key[:4]}...{api_key[-4:]}"

    def _is_keyword_relevant(self, title: str, organization: str, keywords: List[str]) -> bool:
        """í‚¤ì›Œë“œì™€ ê´€ë ¨ì„±ì´ ìˆëŠ”ì§€ í™•ì¸"""
        if not keywords:
            return True  # í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ëª¨ë“  ê²°ê³¼ í¬í•¨

        text = f"{title} {organization}".lower()

        # ì œê³µëœ í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ê´€ë ¨ì„± ìˆìŒ
        for keyword in keywords:
            if keyword.lower() in text:
                return True

        # Seegene ê´€ë ¨ í‚¤ì›Œë“œë„ ì¶”ê°€ë¡œ í™•ì¸ (ë” ë„“ì€ ë²”ìœ„)
        from src.config import crawler_config
        all_seegene_keywords = []
        all_seegene_keywords.extend(crawler_config.SEEGENE_KEYWORDS['korean'])
        all_seegene_keywords.extend(crawler_config.SEEGENE_KEYWORDS['english'])

        for seegene_keyword in all_seegene_keywords:
            if seegene_keyword.lower() in text:
                return True

        return False
